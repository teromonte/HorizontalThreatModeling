%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter4.tex
%% NOVA thesis document file
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter4.tex}%

\chapter{Solution}
\label{cha:solution}

\glsresetall
 
\section{Threat Modeling Protocol for Horizontal Organizations}
\label{sec:protocol}

Horizontal cooperatives face unique security challenges. Without a central
authority, they are vulnerable to attacks that exploit their open, democratic
nature. For example, an attacker might create fake member identities to sway
decisions (a Sybil attack) or abuse the consensus process to cause chaos. At the
same time, horizontality can be a security strength: distributing decisions
means there's no single point of failure. This protocol treats horizontality
as an asset, making security a collective endeavor rather than a top-down
mandate.

\subsection{Key Design Principles}
\label{subsec:key_principles}

\begin{itemize}
    \item \textbf{Transparency}: Security activities (like decisions,
configurations, and incidents) should be visible to members. Open logs and
auditable records ensure nothing happens "behind closed doors, building trust
and accountability among the group.
    \item \textbf{Decentralization}: No single person should have unchecked
power over systems or data. Access and control are distributed. This prevents a
"single admin from being a weak link and avoids creating a digital vanguard
(where a tech-savvy few hold all the keys).
    \item \textbf{Democratic Participation}: All members can participate in
identifying and addressing threats. Security decisions are made through
inclusive discussions or votes, so measures have collective buy-in. This keeps
the process aligned with the coop's democratic governance.
    \item \textbf{Traceability}: Every important action (granting access, making
a change, etc.) leaves an immutable trail. For example, changes can be logged on
tamper-proof ledgers and digitally signed by those who approved them. This way,
if something goes wrong, the coop can trace what happened and who was involved,
without relying on memory or hearsay.
    \item \textbf{Resilience}: The protocol aims to strengthen the coop's
ability to withstand and recover from threats. By eliminating single failure
points and planning for crises (with backup plans and rapid response
mechanisms), the organization stays resilient even under attack. If one
safeguard fails, others are in place to limit damage and bounce back quickly.
\end{itemize}

These principles ensure that improving security will not undermine the
organization nature of the group. Instead, security measures will reinforce
collaboration, shared responsibility, and trust. In practice, this means
building security into everyday cooperative workflows and governance. What
follows is a step-by-step threat modeling process designed with these values in
mind. It's written in accessible language so that any member can take part.
Each step includes guidance and checklists for participatory activities,
and the protocol can be scaled or adapted for organizations of different
sizes and structures.

(Note: While this protocol is inspired by established frameworks like PASTA,
it does not use the formal seven-stage PASTA terminology. Instead, it
presents an equivalent logic in a more accessible format.)

\subsection{Target Audience}
\label{subsec:target_audience}

The protocol is designed for members of horizontal organizations without
specialized cybersecurity expertise. Unlike traditional expert-oriented models,
our protocol emphasizes simplicity and accessibility. It supports stakeholders
involved in decision-making, operational activities, conflict resolution, and
coordination tasks, as well as informal community groups, by providing clear
guidance and intuitive methods for effectively dealing with security threats.


\subsection{Ethics and Protection of Organizations}
\label{subsec:ethics_protection}

When constructing and applying the threat modeling protocol in non-hierarchical
organizations, it is imperative to consider ethical principles as structuring
elements that transcend the merely technical aspect of cybersecurity. Ethical
concerns are based on the explicit commitment to protecting not only
technological integrity, but also the individuals and groups involved in
organizational processes.

A crucial aspect in this context is the responsibility regarding the
confidentiality of sensitive information and the protection of the privacy of
organizational members. The inadvertent exposure of security flaws can cause
significant damage, not only operational, but also personal and social.
Therefore, the protocol must incorporate strict guidelines on the ethical
treatment of identified vulnerabilities, ensuring that such information is
managed in a restricted manner and shared only with authorized individuals or
groups, always respecting the principle of least privilege.

Additionally, it is vital to establish clear internal communication mechanisms
to ensure that any identified vulnerabilities are immediately reported,
mitigated and documented without unnecessary public exposure.

\section{Threat Modeling Process Overview}
\label{sec:threat_modeling_process_overview}

The threat modeling process is broken into eight collaborative steps. In a small
cooperative, most steps can be taken in all-hands meetings or workshops with
everyone. In larger groups, you might delegate initial work to
working groups, but every member should have a chance to review and contribute
at each stage. The process is iterative and modular, so you can adjust the depth
or format of each step based on your organization's size and needs. For each
step below we describe the process and its activities
along with tips to adapt to different situations.

\subsection{Step 1: Establish Context and Goals}
\label{subsec:Step1}

What Are We Protecting?

\subsubsection{Purpose}

Set the stage by agreeing on what assets and operations you need to protect, and
what your security objectives are. This ensures everyone is on the same page
about why you are doing threat modeling and what "success looks like". 

\subsubsection{Activities}

\begin{itemize}
    \item \textbf{Identify Critical Assets}: In a group, list out what is most
valuable to your organization. This can include digital assets (member data,
documents, the website, chat platforms), physical assets (office space, devices,
servers), and intangible assets (the organization's reputation, member trust).
Ask yourselves what would hurt the most if it were stolen, destroyed, or made
public.
    \item \textbf{Outline Key Operations/Workflows}: Describe in simple terms
what the organization does everyday. For example, "We coordinate orders through an
online platform", or "We have weekly meetings to make decisions", or "We run a
community space with an entry badge system". Understanding these workflows helps
identify where disruptions would be most damaging.
    \item \textbf{State Security Objectives and Requirements}: Discuss what
security means for your organization. Do you need to keep member data private? Ensure
your service is always available? Meet any legal regulations like
GDPR? Also consider organization statutes or policies about confidentiality and data
handling. For instance, if your statutes say all financial info must be accessible
to members, that influences how you balance transparency with confidentiality.
    \item \textbf{Define the Scope and Boundaries}: Decide what will and won't
be covered in this threat modeling exercise. Maybe you want to focus on a
particular system and not on unrelated areas.
Or include only digital systems but not physical office
security or vice versa. Clearly defining scope prevents the discussion from
going off-track. It's okay to start with a narrow scope and expand later if needed.
    \item \textbf{Agree on Terminology}: Ensure everyone understands basic terms
you will use. For example, define what you mean by asset, threat, vulnerability,
etc., in plain language. A quick glossary on a whiteboard can help.
\end{itemize}

\subsection{Step 2: Map Systems and Trust Boundaries}
\label{subsec:Step2}

How Do We Work?

\subsubsection{Purpose}

Create a shared understanding of how information and processes flow in your
organization, and where important trust boundaries are. Essentially, draw a map of your
organization's sociotechnical system including people, tech, and their
interactions. In threat modeling, this is similar to diagramming your system
architecture and identifying entry points. For a cooperative, it also means
noting social trust assumptions like who or what we trust and in what ways.

\subsubsection{Activities}

List components and assets like hardware, Software, Data Stores,
People, Roles and Processes. Write these out, possibly in categories.
Essentially, you are enumerating what pieces make up your organization "system".

After that, diagram the Workflow: On a large paper or using a simple online diagram,
sketch how these components connect. Draw who interacts with what:
for example members (people) log into the chat platform (software) to discuss,
or the website communicates with a payment processor. Draw arrows for data flow
or interaction: emails sent, files shared, money transferred, etc. Keep it
understandable. Mark any external services clearly since those are partly
outside your control.

Identify Trust Boundaries, the points in the system where the
level of trust changes. For instance: between an external user and your
internal system like a public website and your internal database; between
a regular member and personal data; social trust boundaries for example
the trust members will not to leak info from private discussions.

On your diagram, draw a dotted line where these boundaries are.
Essentially ask: At what points do we assume things are safe on one side
and potentially risky on the other?

Document Who Has Access to What: Alongside the map, list which roles or people have
access to which assets. E.g., "Only tech team members can access the server", or "All
members can post in the forum", or "Treasurer has the bank account login". This
helps spotlight any concentrations of access and areas where trust is placed in
individuals. Write down services or partners you rely on and mark them on the
diagram for example, your website host, email service, or any software
provider. These are outside your organization but critical; threats can come through them.

\subsection{Step 3: Identify Threats Collaboratively}
\label{subsec:Step3}

What Could Go Wrong?

\subsubsection{Purpose}

Brainstorm all the potential threats and bad things that could happen to the
assets and processes you identified. The goal is a comprehensive list of threat
scenarios, covering both technical attacks and governance risks. At this
stage, quantity is more important than quality. We want to surface as many
ideas as possible, without judging them yet. This step harnesses the diverse
perspectives in your organization: digitally skilled members might think
of hacking scenarios, whereas others might point out process failures or insider
issues that a pure tech focus could miss.

\subsubsection{Activities}

\begin{itemize}

    \item \textbf{Brainstorm in a Safe Environment}:
    
    Gather a group of members, ideally representing different roles or viewpoints,
    for a threat brainstorming session. Set some ground rules: no idea is
    too small and everyone's input is valued. It's important
    people feel comfortable mentioning even unpleasant hypotheticals.
    Assure everyone this is about hypothetical situations,
    not personal distrust.

    \item \textbf{Use Prompts and Creative Tools}:
    Use prompts and creative techniques to explore potential threats by walking
    through the system map from Step 2 and pausing at each component or boundary to
    ask what could go wrong. For example, when examining the database, consider
    whether someone could steal or delete important information, and think about who
    might do this and how. At a boundary like the internet connection, reflect on
    the possibility of an attacker intercepting data in transit or flooding the
    system with excessive traffic. It can also be helpful to introduce the classic
    \gls{stride} as a simple checklist that prompts questions such as
    whether there is a risk of someone impersonating users,
    manipulating records, denying actions they actually performed, exposing private
    data, disrupting service, or somehow gaining privileged access.

    Another useful approach is to incorporate Security Cards, which
    encourage you to think broadly about different attackers
    motivations, methods, and the impacts they could have.
    Motivations might include financial gain, political objectives, disgruntled
    ex-members, or simple mischief. Methods and resources could range from phishing
    emails and malware to physical break-ins, social engineering, or legal threats.
    The potential impacts include service downtime, loss of member trust, financial
    losses, or legal ramifications. By posing these questions and exploring various
    scenarios, the group can avoid focusing solely on obvious IT threats and instead
    uncover possibilities that include internal misuse, human error, or even
    external events that could pose significant risks.

    \item \textbf{Distinguish Different Threat Sources}:
    As ideas emerge, note whether each threat
    scenario is external like a hacker, a virus, a competitor
    or internal coming from within the organization like a member error,
    an insider attack, conflict and miscoordination. There could be a hybrid threat
    where an external actor exploits an internal weakness, like a hacker using
    social engineering to trick a member into giving up access.

    \item \textbf{Write Down Concrete Scenarios}:
    For each idea, capture it as a short scenario description.
    For example:

    \begin{itemize}
        \item "Sybil Attack on decision-making:" An attacker creates multiple fake member
        accounts to gain extra votes in an online poll, influencing the group decision illicitly.
        \item "Insider data leak:" A discontented member with access to sensitive data decides to leak member
        emails and addresses to the public.
        \item "Ransomware on shared drive:" Malware infects a member's computer and encrypts the shared cloud
        drive files, making them inaccessible until a ransom is paid.
        \item "Lost credentials:" A member who manages the Twitter account leaves suddenly, and no one else has
        the password The group loses control of its own social media.
        \item "Miscoordination outage:" In a crisis, no one is designated to respond, because everyone thinks
        someone else will, and a small issue like a certificate expiry escalates, taking the website offline
        for days.
        \item "Service provider failure:" The third-party platform goes
        down or is compromised, affecting the organization's operations.
    \end{itemize}

    Aim for a broad list, covering cyber-attacks, human mistakes, physical events
    like the office gets robbed or a server gets wet, and governance failures. Don't
    worry at this stage if some scenarios seem very unlikely. List them as if someone
    is concerned about it.

    \item \textbf{Ensure Social/Process Threats are Included}:
    Cooperatives might face threats like quorum manipulation (exploiting the rules
    of consensus/voting), abuse of emergency powers (someone invoking a crisis to
    grab authority), or "digital vanguard" accumulation (one person quietly gaining
    control of many digital assets because no one else steps up). Include these in
    your brainstorming. For example, "Member X holds all the keys and if they quit
    or go rogue, we're locked out" is a valid threat scenario to record (it's an
    internal risk).

\end{itemize}

\subsection{Step 4: Profile Adversaries}
\label{subsec:Step4}

Who Might Attack Us?

\subsubsection{Purpose}

Humanize the threats by creating adversary personas that represent fictional
characters that represent types of attackers or sources of threats. This helps the
group to think from an attacker's perspective and ensures you consider the
motivations and capabilities behind the threats. In this step we focus on personas for
intentional actors. Developing these profiles makes later analysis more
concrete and relatable.

\subsubsection{Activities}

\begin{itemize}
    \item Identify Key Threat Actors: Look at the threat scenarios from Step 3 and ask, "Who would
    carry out these actions?". You will find a few recurring archetypes. For example:
    a hacker or vandal with no connection to the organization, motivated by profit or
    entertainment; a state or corporate actor who opposes the organization's
    mission; a disgruntled or former member with inside knowledge and intent to
    cause harm; or a careless insider who, even without bad intentions, may
    introduce risks through mistakes or negligence. It is also important to
    distinguish between adversaries with technical skills—such as a mid-level
    hacker—and those who act in a non-technical manner, such as an insider who
    manipulates rules or processes to his or her own advantage.

    \item For each type of actor, it is recommended to create a brief profile that
    includes their name and role, for example: "Mallory, the Malicious Insider" or "Ingrid,
    the Unaware member", as well as describing their motivations such as profit,
    revenge, or simply wanting to harm the organization and their capabilities or
    resources, from intrusion techniques to privileged insider knowledge. In
    addition, it is important to indicate what methods this actor might use for example:
    phishing, vulnerability exploitation, manipulation of legitimate credentials.
    and relate each persona to specific scenarios from the threat list, highlighting
    how their actions fit into the group dynamics.

    \item When documenting personas, it is recommended to dedicate a page or slide to each
    adversary, including an illustrative image to make it more memorable, avoiding
    photographs of real people, in order to avoid generating bias.
    The text should be clear and accessible, emphasizing that the purpose is
    purely internal, without the need for excessive formality. For example, when
    describing Mallory, the resentful ex-member, it would be useful to indicate her
    background (she left after a conflict, but still retains some credentials), her
    motivations (revenge, demonstrating security flaws), her skills (she knows the
    system well, although she is not an expert in hacking), the most likely actions
    (using leftover credentials, masquerading as another member, spreading
    disinformation), and the assets targeted (member directory, internal
    communication channels, decision-making platforms). The same pattern can be
    applied for each main type of adversary identified.
    
    \item Include at Least One Insider Persona: It may be uncomfortable but include a scenario of a malicious or
    careless insider. Cooperatives thrive on trust, yet history shows sometimes insiders can cause harm (intentionally
    or not). By creating, say, "Insider Irene" who is well meaning but prone to bypassing rules.
    Make it clear this is hypothetical to improve security for everyone.
    
    \item Use Personas in Discussion: Once you have personas, you can use them in future steps. For example, when
    thinking about mitigations, you might ask "Would this stop Mallory?" or "How would we detect Oscar's actions?"
    Personas help ground these discussions.
\end{itemize}

\subsection{Step 5: Analyze Attack Scenarios}
\label{subsec:Step5}

How Could Attacks Happen?

\subsubsection{Purpose}

Now take your threat list and personas, and dive deeper into how those threats
could play out step-by-step. This scenario analysis helps you understand the
sequence of events in an attack and where your weak points are. In practice,
this means building attack narratives or attack trees and possibly simulating
some scenarios in an exercise. This step turns abstract threats into
concrete stories, revealing exactly what vulnerabilities enable an attack and
how severe the consequences would be. It's a bridge from brainstorming to
action, by visualizing attacks, you prepare to figure out defenses.

\subsubsection{Activities}

\begin{itemize}   
    \item Construct Attack Trees: Pick a high-priority threat scenario (you will prioritize
    formally in the next step but start with one that seems obviously serious or emblematic).
    For example, "unauthorized access to the member list", an attack tree is
    constructed with that objective at the root. From there, possible paths are identified.
    For example, an external attacker exploits a vulnerability in the system, gains administrator privileges, and
    extracts the data; or a malicious insider uses their legitimate access to copy
    and disclose the information; or an attacker convinces someone to give up their
    password, logs in with the victim's account, and navigates to the data. The
    figure below illustrates these branches. At each stage, it highlights where
    defenses already exist, where they fail, and which points require attention. The
    level of detail should be sufficient to reveal relevant decisions and
    vulnerabilities, while maintaining the clarity of the analysis.

    \item Conduct Tabletop Simulations: For some scenarios, especially ones involving multiple people or
    processes, do a role-play tabletop exercise. Assemble a small group and narratively walk through the
    scenario: Assign someone to play the adversary (using one of your personas) and others to play
    defenders or just observers. Example: Simulate "Sybil attack during an online vote." Narrator says:
    "It's the day of a big proposal vote. Unknown to the group, Mallory has created three fake member identities over
    the last month." Then step by step: "Vote opens. Mallory votes as herself and as Alice, Bob, and
    Charlie (her fake profiles). The system tallies four votes from what appears to be four people."
    Discuss: Would anything at that moment flag an issue? How would the organization notice? Perhaps another
    member finds it odd that there were three new members who never spoke but voted. Or maybe nobody
    notices until later. Continue: "The vote passes with those extra votes. Later, someone questions the
    outcome…" This kind of storytelling helps highlight if your current processes have detection or not.
    Participants can chime in with "At that point, I would check the member list…" or ask "Do we verify
    new online voters somehow?" Write down these insights. The idea is to practice an attack in theory
    to see where your response or system breaks. It's much cheaper to find gaps this way than during
    a real incident.
    
    \item Identify Vulnerabilities at Each Step: As you chart out these scenarios, explicitly list the
    vulnerabilities or weak points that make the attack possible. These could be technical (e.g.
    "Outdated plugin allows injection", "No backup exists for database"), or organizational (e.g. "New
    members are not verified, allowing fakes", "Only one person knows how to reset the server"). Also
    note any existing controls and whether they work: For each step in the scenario, ask "What should
    stop this? Do we have something to stop it? Does it actually stop it or can it be bypassed?"
    E.g., in the Sybil scenario: Vulnerability = lack of strict member verification in the
    voting system. Existing control = new accounts require admin approval (does that happen? maybe
    someone auto-approved without checks).
    In the hacker scenario: Vulnerability = software not patched; Control = we have a
    firewall, but if the attack comes through a web port, firewall doesn't stop it; or Control = we rely
    on strong passwords, which might not help if exploit exists.
    Write these vulnerabilities next to the steps or in a separate list mapped to the
    scenario. This will directly feed into deciding mitigations.

    \item Assess Impact and Likelihood for Scenarios: As part of analysis, discuss for each scenario,
    how bad would it be if this happened? and how likely is it to happen? Use qualitative terms for example:
    For ransomware encrypting files the Impact is High because of data loss but likelihood maybe Medium
    if members are generally careful. For sybil attack the impact is High on governance
    legitimacy but likelihood may be Low to Medium depending on how easy it is to create fake accounts in your
    system.

    \item Leverage Past Incidents: If your coop or similar groups have experienced incidents,
    incorporate those into scenarios. "This happened before, could it happen again in a worse way?"
    Learning from near-misses or history makes scenarios very concrete. For example, "Last year someone
    guessed our Twitter password, what if they had tweeted offensive stuff? Let's play out that
    scenario."
\end{itemize}

\subsection{Step 6: Prioritize Risks Together}
\label{subsec:Step6}

Which Problems Matter Most?

\subsubsection{Purpose}

Not all threats are equal. In this step, the group evaluates all the
identified threat scenarios and decides which ones to address first. This is
essentially a risk analysis and ranking. Risk is usually judged by two factors:
how severe the impact would be and how likely the threat is to occur. By scoring
or discussing these, the group can focus on the most critical issues.
Importantly, this is done participatorily, everyone's perspective on what is
important is considered, keeping the process democratic. The output will be a
clear list of top-priority risks that the organization will invest effort in mitigating.

\subsubsection{Activities}

\begin{itemize}   
    \item Set Risk Criteria (Impact and Likelihood): Before prioritizing risks,
    the group should build a common understanding of what impact
    and probability mean in their context. High impacts are those that
    threaten the existence of the organization, violate laws, or seriously undermine
    the trust of members; medium impacts cause manageable disruptions; and low
    impacts cause only occasional inconveniences. Similarly, a threat may be
    considered high probability if there is concrete evidence that it could occur
    easily, medium if it depends on specific conditions, and low if it is unlikely
    or requires great sophistication. Using simple scales (such as high, medium, and
    low) is often sufficient, as long as the meanings are collectively discussed.

    \item Evaluate Each Threat Scenario: Go through the list of scenarios (from Step 3/5) one by one and discuss
    "If this happened, how bad would it be? (Impact)" and "How likely is it to happen given what
    we know? (Likelihood)". Encourage input, maybe the IT person knows that a certain attack is actually quite hard, so
    likelihood is low; but a governance person might point out that even if low, that attack's impact on member
    trust would be catastrophic. Both points are valid. You can do this discussion informally and just
    mark each scenario High/Med/Low, or use a more structured method like voting or rating.
    Aim for consensus or at least a general agreement on where each major threat sits.
    
    \item Rank the Risks: Based on the evaluations, identify the top tier of risks that demand action. These
    are typically the scenarios with High impact (even if low likelihood) and those with High likelihood (even if
    medium impact), especially anything that's High in both. Often you'll find a handful that stand out as "we
    absolutely must address these."
    Also pay attention to "low-hanging fruit", a scenario that might be Medium risk but can be
    fixed easily. Sometimes the group might say, "This isn't our worst problem, but it's so simple to prevent that
    we should just do it". Example: "Data loss due to no backup" might be medium likelihood and medium impact,
    but the fix is straightforward, so you might prioritize it early.
    You might end up with categories like: Critical (must fix ASAP), Moderate (plan to address),
    Acceptable or Low (acknowledge but no immediate action).

    \item Document Rationale: For transparency, write down a brief note next to each top risk about why it's
    ranked high and what the group's judgment was. E.g., "Sybil attack on voting – High Impact (could undermine
    our governance legitimacy), Low Likelihood (member sign-up currently requires approval, and we've seen no
    attempts) – Still a Top Concern because of impact on trust." This record helps if later someone asks "Why are
    we focusing on this threat over that one?" Everyone can see the reasoning agreed upon.
    
    \item Verify Against Goals: Revisit Step 1's assets and objectives. Ensure that the top risks you've
    chosen indeed relate to what you care about most. If an important asset has no high risks listed,
    double-check: did we miss a threat for it, or is it truly low-risk? Conversely, if a scenario came up high
    risk but involves something not central to your mission, consider if it's truly a priority. This sanity check
    keeps the process aligned with cooperative values and priorities.
    
    \item Obtain Group Endorsement: Formally or informally, get the group's nod that "Yes, these are the
    threats we're most concerned about." In a smaller coop, that might be as simple as everyone saying "Sounds
    right." In a larger one, you might do a quick vote to approve the risk ranking or have the board
    committee ratify it. This is important for accountability, it shows the decision on what to do next was made
    collectively.
\end{itemize}

\subsection{Step 7: Mitigations and Governance Decisions (How Do We Fix or Prevent Issues?)}
\label{subsec:Step7}

\subsubsection{Purpose}

For each of the top-priority threats, decide on countermeasures and integrate
those decisions into the coop's action plan. In other words, figure out what
security measures to implement and how to approve and enforce them
democratically. This step is where you turn analysis into concrete changes:
technical fixes, new or improved policies, training, etc. It's also where you
make sure that implementing these fixes doesn't accidentally centralize power or
violate cooperative principles. We design the mitigations to both reduce risk
and fit into the coop's governance structure.

\subsubsection{Activities}

\begin{itemize}   

    \item Brainstorm Mitigation Options: For each high-priority threat scenario, list possible ways to mitigate
    it. Mitigations can fall into different categories:
        \begin{itemize}   
            \item Technical solutions: e.g. apply a software patch or upgrade, enable two-factor authentication
    for logins, encrypt data at rest, set up an intrusion detection system, require multi-signature for financial
    transactions.
            \item Process or workflow changes: e.g. institute a checklist for onboarding/offboarding members (so
    fake identities are caught and departing members lose access promptly), establish a routine backup procedure,
    require a second pair of eyes (peer review) before pushing changes to the website, add a step to verify any
    important request (like fund transfers) through a secondary channel.
            \item Education and training: e.g. do a phishing awareness session so members can spot suspicious
    emails, create a quick guide on how to choose strong passwords or use the password manager the coop adopts,
    run an orientation on security policies for all members annually.
            \item Governance/policy measures: e.g. create a policy that "All admin passwords are stored in our
    shared password manager vault accessible by at least 3 people," or "For emergency decisions, at least 2 out of
    3 designated responders must agree," or "Every proposal in the decision platform must be made by a verified
    member identity." Essentially, rules that formalize the security practices.
        \end{itemize}
    
    Use the adversary personas as a lens: ask "If we do this, would it stop or deter [Persona] from succeeding?"
    For instance, to counter Mallory (disgruntled ex-member) misusing credentials, one mitigation might be
    "immediately deactivate accounts when someone leaves (offboarding policy)." To counter Oscar (outside hacker)
    exploiting a bug, mitigation is "keep software updated, and maybe run security scans." To counter the Sybil
    scenario, mitigation could be "implement stricter member verification for online voting (like each account
    must link to a real person's membership record)."

    List multiple options if they exist, then discuss feasibility: How hard or expensive is it? Does it require
    outside help or new tools? Does it slow down any workflow (introduce friction)? Does it align with our values
    (e.g. a mitigation "ban all new members for safety" would harm the coop's openness, so probably unacceptable)?
    
    \item Collective Deliberation on Mitigations: For each threat and its potential solutions, discuss with the
    group (or relevant sub-group) to choose the best course of action. This might happen in a dedicated security
    meeting or as part of regular meetings. Ensure to involve those who will be responsible for implementing or
    affected by the change. For example, if the mitigation is "use a new encrypted chat tool," the IT team and
    regular members should both weigh in (IT on how to implement, members on usability).
    Some mitigations might be contentious (maybe someone feels requiring 2FA is too burdensome, or rotating admin
    duties is too chaotic). Strive for consensus by addressing concerns: perhaps provide alternatives or phased
    approaches. If consensus can't be reached, use your coop's normal decision process (majority vote, etc.) to
    finalize the decision on that mitigation.
    Important: Document the decision for each major mitigation: the group agrees "Yes, we will do X to address
    threat Y." This can be recorded in meeting minutes or an action plan.
    
    \item Assign Responsibility and Resources: For each chosen mitigation, decide who will carry it out and by
    when. Since this is a horizontal organization, avoid dumping everything on one person. Instead:
        \begin{itemize}   
            \item Spread technical tasks among tech-skilled members or a tech working group, but maybe pair them
    with a non-tech member for transparency.
            \item Assign policy drafting to a small team that includes people from governance and operations.
            \item If training is needed, maybe identify a member who's good at teaching, or an external expert if
    budget allows.
            \item Ensure each mitigation has an "owner" or small team responsible for seeing it through. This
    distributes responsibility and builds shared security knowledge.
            \item If certain mitigations require budget (e.g. buying a security certificate, or paying for a backup
    service), note that and ensure it goes through the normal budgeting process of the coop.
        \end{itemize}
    
    Essentially, integrate these tasks into your coop's project management – treat them like important initiatives
    with accountability. This also helps avoid the situation where plans are made but no one follows up.
    
    \item Implement with Democratic Oversight: As mitigations are implemented, keep the group informed. For
    example:
        \begin{itemize}   
            \item If the tech team is deploying a new secure tool, they should report progress at meetings or in
    the group chat.
            \item If a policy is drafted (e.g. an "Acceptable Use Policy" for members), circulate it for comments and
    formally adopt it through the coop's decision mechanism.
            \item Unity in execution: Once a security measure is agreed on, all members should cooperate in making it
    work, even if it's a bit inconvenient. This might mean everyone actually enables 2FA on their accounts, or
    actually uses the new password manager, not just a few. Culturally, frame it as "we all agreed to this because
    it protects all of us." When needed, gently remind folks that this was a collective decision (the democratic
    centralism idea: we discussed openly, now we implement uniformly).
        \end{itemize}
    
    \item Plan for Emergency Situations (Temporary Delegation): One big governance aspect to settle is: How will
    we handle a security emergency or critical incident? In a crisis (like an active cyber-attack, or a major
    breach in progress), organizations might need to act faster than usual consensus allows. The protocol encourages
    having a pre-agreed emergency response team or procedure:
        \begin{itemize}   
            \item Decide if you will appoint a small Security Incident Response Team (SIRT) or similar. This could
    be, say, 3 trusted members with the technical know-how (or quick learners) who are empowered to make snap
    decisions when an incident is detected.
            \item Define the scope and limits of their power: e.g., "They can temporarily shut down a server, or
    revoke someone's access, or spend up to X euros on emergency help, without full group approval in that
    moment." Also define the timeframe: their actions are meant to contain the issue, and must be reported ASAP to
    the membership and reviewed, say, within 24-48 hours.
            \item This delegation is temporary and accountable: as soon as the immediate threat is handled, they must
    explain their actions to the whole coop (transparently via an incident report), and if any decision needs to
    be permanent (like firing an IT provider or changing a policy), it goes to the group for normal
    decision-making.
            \item If your coop is small, your "team" might just be the few people who know what to do, but still
    explicitly acknowledge it ("If something blows up, Alice and Bob will take charge for the moment, and inform
    everyone as they do").
        \end{itemize}
    
    Having this plan prevents paralysis in a crisis and avoids someone unilaterally taking over just because
    nothing was defined. Everyone knows in advance who will act and trusts that it's been agreed upon.
    
    \item Integrate Security into Governance Documents: Once decisions are made (normal mitigations or emergency
    roles), codify them. Update your coop's handbook, wiki, or policy docs to include the new security measures.
    For example, add an "Access Control Policy" section that outlines how accounts are managed collectively, or a
    note in the decision-making section that describes the emergency procedure. This ensures new members will
    learn these practices during onboarding, and it institutionalizes the security improvements.
    
    \item Set Review Milestones: Before closing this step, decide when you will check back on these mitigations.
    It could be:
        \begin{itemize}   
            \item A quick check-in at the next general meeting ("Did we do what we said for threat X? Is it
    working?").
            \item A formal review after 3 or 6 months to see progress on longer tasks.
            \item Incorporating it into an annual coop review or similar. By scheduling a follow-up, you create
    accountability and also acknowledge that mitigations may need tweaking.
        \end{itemize}
    
    \end{itemize}

\subsection{Step 8: Ongoing Improvement and Monitoring (How Do we Keep Alive Security?)}
\label{subsec:Step8}

\subsubsection{Purpose}

Threat modeling isn't a one-time project – especially in a cooperative that
evolves. Step 8 is about making security a continuous, integrated part of your
coop's governance and operations. This means regularly monitoring for new
threats, reviewing the effectiveness of your defenses, and adjusting to changes,
all without losing the cooperative spirit. In short: build a living security
program that grows and adapts with your organization.

\subsubsection{Activities}

\begin{itemize}   

    \item Include Security in Routine Governance: Treat security as a standing topic in meetings. For
    example:
        \begin{itemize}
            \item In your monthly general meeting or weekly check-in, have a brief agenda item like
            "Security and Privacy Check." This could be a quick report: "Any incidents or near-misses this
            month? Any new vulnerabilities found or new tools added that we should consider in our model?"
            \item Quarterly or semi-annually, do a slightly deeper review. This could coincide with other
            reviews (financial, operational). Go over the threat list: have any new threats emerged? (Perhaps
            the coop started using a new platform – that introduces new risks to consider.) Are there threats
            that can be downgraded because of improvements? Basically, keep the threat model updated.
            \item If you have a rotating security committee, they can take charge of preparing these updates.
            But even if not, someone can volunteer each time to gather relevant info.
        \end{itemize}

    \item Maintain Logs and Audit Trails: Earlier we emphasized logging and traceability. Make sure
    those logs (system logs, decision logs, access records) are actually being looked at. For example:
        \begin{itemize}
            \item If you set up an immutable log of administrative actions (like who changed what settings),
            maybe once a month a couple of members review it to see if all actions were expected and legit.
            \item If you require multi-signature on an account, periodically check that the rule is being
            followed (no one found a shortcut).
            \item Conduct an internal audit once a year: pick a couple of key policies and verify they are
            enforced. E.g., "Check 5 random user accounts to ensure they all have 2FA on as required," or
            "Verify that all ex-members in the past year have indeed been removed from our systems within the
            agreed 24 hours of departure." Such audits can be done by peers (any member can do it following a
            script) and results shared openly: "We checked and found 1 of 5 accounts didn't have 2FA; we helped
            that member set it up."
        \end{itemize}
    This might sound formal, but it can be lightweight and it greatly helps catch when practices slip.
    Because organizations have no boss checking up, the members collectively check up in a transparent way.

    \item Periodic Retraining and Onboarding: Over time, members may forget certain security practices
    or new people join who weren't part of the initial threat modeling. Address this by:
        \begin{itemize}
            \item Creating a short "Security Handbook" or section in your member handbook that summarizes
            key policies ("We use a shared password manager; here's how to get access," "Never share your login
            links with others," "Report any lost device immediately," etc., and also the why – referencing
            threats like "to prevent incidents like [scenario]" which makes it relatable).
            \item Holding a yearly refresher workshop or sending a summary of "Our coop's top 5 threats and how
            we mitigate them – reminders for all members."
            \item Simulating a phishing email test or an impromptu drill (with consent) to keep awareness
            sharp, then discussing the results in a blameless way ("Hey, 3 of us clicked that fake link – let's
            go over how to spot those signs!").
            \item Updating onboarding processes: when new members join, include a quick orientation on security
            norms (for instance, how accounts are created, who to ask for tech help, basic do's and don'ts). If
            they know from day one that "security is everyone's responsibility here," it sets a good culture.
        \end{itemize}

    \item Adapt to Changes in the Coop: If your cooperative grows from 5 members to 50, or starts a new
    project, revisit the threat model more formally. New scale or activities can mean new threats:
        \begin{itemize}
            \item With more members, the risk of insider issues might increase simply by volume, and
            communication overhead grows – maybe you need more structured processes or automation.
            \item With new projects (say you start handling money for members, or you open a second location),
            add those assets and processes to the model and run through the threat steps again in a lighter
            form.
            \item Schedule a full threat modeling redo or refresh perhaps annually or bi-annually. It doesn't
            have to start from scratch each time; you can use the previous notes and just update. But having a
            cycle ensures that, for example, in two years you're not using the exact same assumptions while the
            world changed around you.
        \end{itemize}

    \item Engage with the Wider Community: Horizontal organizations can learn a lot from each other. Consider
    sharing non-sensitive parts of your security approach with other cooperatives or participating in
    forums/discussion groups about security in decentralized organizations. You might discover common
    threats others have seen, or tools specifically helpful for organizations (for example, an open source tool
    for consensus that has anti-Sybil features, etc.). By contributing your experiences (without giving
    away your secrets), you also help the movement as a whole become more secure. This external input
    can be brought back to your coop's next threat modeling session ("We heard another coop had an issue
    with X, should we consider that scenario for us?").

    \item Monitor and Respond to Evolving Threats: Stay informed about general cybersecurity news that
    might affect you (e.g., a new vulnerability in a software you use – ensure someone updates it; a
    wave of phishing targeting small nonprofits – maybe alert members to be extra careful). Since no one
    person is "the security officer," create channels where such information can be shared. Maybe a
    security Slack/Matrix channel or an email list for anyone who finds something relevant. Collective
    eyes can watch more ground.

    \item Governance Feedback Loop: Evaluate how well the balance of democracy and efficiency in your
    security process is working:
        \begin{itemize}
            \item After any incident or even after a year, ask: Did our emergency response plan work? Did
            anyone feel left out of the loop unnecessarily? If so, adjust the protocol.
            \item Are members generally comfortable with the security measures or is there grumbling about
            complexity? If many find it too cumbersome (say the multi-sig process is taking too long for routine
            tasks), maybe tweak the thresholds or invest in a smoother tool. Always weigh these changes against
            the risk: maybe it's fine to ease up if the threat is low, or maybe the group agrees the
            inconvenience is worth the protection.
            \item Essentially, treat the security policies themselves as living documents subject to the coop's
            governance. Amend them when needed, just like you would bylaws or other procedures, through the
            collective decision process.
        \end{itemize}
\end{itemize}

\subsection{Participation Tips}
\label{subsec:participation_tips}

A key to success is ensuring that the entire group feels comfortable and
motivated to contribute at each stage, and this requires a culture that values
collaboration and mutual respect. In small cooperatives, carrying out
activities in a single meeting with everyone present tends to work well, as it
facilitates a sense of belonging and avoids the need for multiple sessions. If
the cooperative is larger, using short questionnaires or smaller discussion
groups before consolidating the results in a plenary session can reduce
dispersion and allow each person to express themselves without fear of judgment.
It is essential that those who are more proficient in technology do not
monopolize discussions, so it is worth directly questioning members who tend to
speak less, asking how they perceive the impact of a given threat or
countermeasure. When seeking consensus on risk prioritization, it is natural for
differences of opinion to arise; frank conversation is part of the democratic
process, and in cases where the group cannot reach an agreement, an anonymous
vote or score can prevent undue pressure. In tabletop simulations or when
creating adversary personas, a lighthearted and creative atmosphere helps to
build plausible scenarios without generating tension, always remembering that
the examples are hypothetical and not direct accusations against colleagues. It
is equally important to keep a clear record of each decision, so that everyone
knows why certain choices were made and how they can review them in the future
if necessary. After implementing defenses, encouraging members to share any
difficulties or points for improvement promotes both collective learning and
genuine adherence to new practices. Finally, distributing responsibilities among
different people or subgroups avoids overload and reinforces the sense of
collective ownership of security, maintaining a horizontal spirit at every step.

\section{Security and Governance Requirements}
\label{sec:security_governance_requirements}

The proposed protocol for horizontal organizations must meet security and
governance requirements that ensure both participatory inclusion and robustness
against internal and external threats. In decentralized structures, where the
absence of formal hierarchy can be seen as both an advantage and a challenge, it
is imperative that the protocol be designed to integrate mechanisms that
preserve horizontality without compromising organizational resilience.
Transparency, in this context, emerges as one of the central pillars
\cite{Colbac}. All events related to the authorization of actions or
modifications must be recorded in an immutable manner, ensuring that actions can
be reliably audited by any member of the organization. These immutable records,
built on technologies such as blockchain or similar cryptographic structures,
ensure traceability and eliminate the possibility of unauthorized changes,
maintaining cohesion between organizational principles and technological
mechanisms.

Democratic participation also plays a fundamental role in the design of the
protocol \cite{Colbac}. In a horizontal organization, decisions must reflect the
collective will, and to this end, the protocol must integrate digital voting
systems that guarantee both the privacy and security of votes \cite{Colbac}. In
addition, it must be possible to temporarily delegate authority to individuals
or groups to deal with situations that require specific expertise, always
ensuring that such delegation can be revoked and that records of actions are
accessible for collective audit \cite{Colbac}.

Another crucial aspect is the flexibility of the protocol, especially in
scenarios where the organization needs to switch between centralized and
distributed governance modes. This transition capacity must be implemented in a
way that the levels of centralization are temporary and properly tracked,
ensuring that control can quickly return to the collective. To this end, the
protocol must provide mechanisms such as emergency tokens, which allow the
execution of critical actions in exceptional situations, as long as such actions
are recorded and subject to retroactive validation by the members of the
organization \cite{Colbac}.

For the protocol to be scalable, it is essential that it supports organizations
of different sizes and degrees of complexity. This includes implementing
distributed validation systems that allow collaborative verification of actions
without burdening individuals or single points of control \cite{Colbac}.
Furthermore, threat modeling should be iterative and adaptive, incorporating
techniques such as simulations based on real-world scenarios to identify
emerging vulnerabilities and adjust countermeasures accordingly. These
mechanisms ensure that the protocol remains functional and effective even when
the organizational scale increases or its internal dynamics change.

\section{Evaluation Strategy}
\label{sec:evaluation_strategy}

The evaluation of the proposed protocol will be conducted through an
experimental and comparative approach, involving real case studies in
organizations with different degrees of horizontality. The main objective is to
validate the effectiveness of the protocol in identifying, mitigating and
preventing threats in horizontal organizational contexts, directly comparing its
performance with established frameworks, such as \gls{stride}.

Candidate organizations will be selected to represent a variety of horizontal
structures, ensuring diversity in power distribution, size and operational
complexity. Participants from each organization will receive structured training
sessions covering both the proposed protocol and \gls{stride}, ensuring
familiarity and a level playing field for comparison.

\textbf{Parallel Threat Modeling Sessions:}
Each organization will conduct simultaneous threat modeling sessions using both
the proposed protocol and \gls{stride} in identical scenarios. These sessions
will be observed to systematically document the process and collect data,
analyzed according to the following clearly defined metrics:

\begin{itemize}
\item \textbf{Precision}: The ratio of valid threats correctly identified to the
total number of threats identified by the protocol.
\item \textbf{Coverage (Recall)}: The proportion of existing threats identified
by the protocol relative to a reference set established by experts.
\item \textbf{Operational Efficiency}: Total time (latency) required to complete
each phase of the threat modeling process, including identification, analysis,
and mitigation planning.
\item \textbf{Usability}: Participants' opinions on the ease of use, clarity,
and overall effort required to learn and effectively apply the protocol.
\end{itemize}

By systematically applying these clearly defined metrics and evaluation steps,
this strategy ensures a comprehensive comparative analysis, providing robust
empirical evidence on the effectiveness of the protocol relative to \gls{stride}
in horizontal organizations.

\section*{}
Chapter 4 presented the preliminary design of a protocol specifically aimed at
threat modeling in horizontal organizations, detailing fundamental security and
governance requirements, such as mechanisms for democratic participation,
temporary delegation of authority, and auditable records. The importance of
aligning technological and organizational processes to ensure robustness against
internal and external threats was highlighted. Based on this conceptual
development, Chapter 5 summarizes the main results achieved by this research,
critically evaluating the proposed protocol, identifying its contributions in
relation to traditional methodologies, and exploring practical scenarios for
future validations in real environments.
