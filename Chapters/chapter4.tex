%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter4.tex
%% NOVA thesis document file
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter4.tex}%

\chapter{Solution}
\label{cha:solution}

\glsresetall
 
\section{Threat Modeling Protocol for Horizontal Organizations}
\label{sec:protocol}

Horizontal cooperatives face unique security challenges. Without a central
authority, they are vulnerable to attacks that exploit their open, democratic
nature. For example, an attacker might create fake member identities to sway
decisions (a Sybil attack) or abuse the consensus process to cause chaos. At the
same time, horizontality can be a security strength: distributing decisions
means there's no single point of failure. This protocol treats horizontality
as an asset, making security a collective endeavor rather than a top-down
mandate.

\subsection{Key Design Principles}
\label{subsec:key_principles}

\begin{itemize}
    \item \textbf{Transparency}: Security activities (like decisions,
configurations, and incidents) should be visible to members. Open logs and
auditable records ensure nothing happens "behind closed doors, building trust
and accountability among the group.
    \item \textbf{Decentralization}: No single person should have unchecked
power over systems or data. Access and control are distributed. This prevents a
"single admin from being a weak link and avoids creating a digital vanguard
(where a tech-savvy few hold all the keys).
    \item \textbf{Democratic Participation}: All members can participate in
identifying and addressing threats. Security decisions are made through
inclusive discussions or votes, so measures have collective buy-in. This keeps
the process aligned with the coop's democratic governance.
    \item \textbf{Traceability}: Every important action (granting access, making
a change, etc.) leaves an immutable trail. For example, changes can be logged on
tamper-proof ledgers and digitally signed by those who approved them. This way,
if something goes wrong, the coop can trace what happened and who was involved,
without relying on memory or hearsay.
    \item \textbf{Resilience}: The protocol aims to strengthen the coop's
ability to withstand and recover from threats. By eliminating single failure
points and planning for crises (with backup plans and rapid response
mechanisms), the organization stays resilient even under attack. If one
safeguard fails, others are in place to limit damage and bounce back quickly.
\end{itemize}

These principles ensure that improving security will not undermine the
organization nature of the group. Instead, security measures will reinforce
collaboration, shared responsibility, and trust. In practice, this means
building security into everyday cooperative workflows and governance. What
follows is a step-by-step threat modeling process designed with these values in
mind. It's written in accessible language so that any member can take part.
Each step includes guidance and checklists for participatory activities,
and the protocol can be scaled or adapted for organizations of different
sizes and structures.

(Note: While this protocol is inspired by established frameworks like PASTA,
it does not use the formal seven-stage PASTA terminology. Instead, it
presents an equivalent logic in a more accessible format.)

\subsection{Target Audience}
\label{subsec:target_audience}

The protocol is designed for members of horizontal organizations without
specialized cybersecurity expertise. Unlike traditional expert-oriented models,
our protocol emphasizes simplicity and accessibility. It supports stakeholders
involved in decision-making, operational activities, conflict resolution, and
coordination tasks, as well as informal community groups, by providing clear
guidance and intuitive methods for effectively dealing with security threats.


\subsection{Ethics and Protection of Organizations}
\label{subsec:ethics_protection}

When constructing and applying the threat modeling protocol in non-hierarchical
organizations, it is imperative to consider ethical principles as structuring
elements that transcend the merely technical aspect of cybersecurity. Ethical
concerns are based on the explicit commitment to protecting not only
technological integrity, but also the individuals and groups involved in
organizational processes.

A crucial aspect in this context is the responsibility regarding the
confidentiality of sensitive information and the protection of the privacy of
organizational members. The inadvertent exposure of security flaws can cause
significant damage, not only operational, but also personal and social.
Therefore, the protocol must incorporate strict guidelines on the ethical
treatment of identified vulnerabilities, ensuring that such information is
managed in a restricted manner and shared only with authorized individuals or
groups, always respecting the principle of least privilege.

Additionally, it is vital to establish clear internal communication mechanisms
to ensure that any identified vulnerabilities are immediately reported,
mitigated and documented without unnecessary public exposure.

\section{Threat Modeling Process Overview}
\label{sec:threat_modeling_process_overview}

The threat modeling process is broken into eight collaborative steps. In a small
cooperative, most steps can be taken in all-hands meetings or workshops with
everyone. In larger groups, you might delegate initial work to committees or
working groups, but every member should have a chance to review and contribute
at each stage. The process is iterative and modular, so you can adjust the depth
or format of each step based on your organization's size and needs. For each
step below, we outline the purpose, activities, and participatory approach,
along with tips to adapt to different situations.

\subsection{Step 1: Establish Context and Goals (What Are We Protecting?)}
\label{subsec:Step1}

\subsubsection{Purpose}

Set the stage by agreeing on what assets and operations you need to protect, and
what your security objectives are. This ensures everyone is on the same page
about why you are doing threat modeling and what "success looks like. In
traditional terms, this is like defining the business/mission objectives and
scope for security.

\subsubsection{Activities/Checklist}

\begin{itemize}
    \item \textbf{Identify Critical Assets}: As a group, list out what is most
valuable to your organization. This can include digital assets (member data,
documents, the website, chat platforms), physical assets (office space, devices,
servers), and intangible assets (the organization's reputation, member trust, know-how).
Ask yourselves: "What would really hurt if it were stolen, destroyed, or made
public? Write these down for all to see.
    \item \textbf{Outline Key Operations/Workflows}: Describe in simple terms
what the organization does day-to-day. For example, "We coordinate orders through an
online platform, or "We have weekly meetings to make decisions, or "We run a
community space with an entry badge system. Understanding these workflows helps
identify where disruptions would be most damaging.
    \item \textbf{State Security Objectives and Requirements}: Discuss what
security means for your organization. Do you need to keep member data private? Ensure
your service is always available? Meet any legal/privacy regulations (like
GDPR)? Also consider organization statutes or policies about confidentiality and data
handling. For instance, if your statutes say all financial info must be accessible
to members, that influences how you balance transparency with confidentiality.
Jot down these objectives and any compliance requirements.
    \item \textbf{Define the Scope and Boundaries}: Decide what will and won't
be covered in this threat modeling exercise. Maybe you want to focus on a
particular system (e.g. your member database and communication tools) and not on
unrelated areas. Or include only digital systems but not physical office
security or vice versa. Clearly defining scope prevents the discussion from
going off-track. It's okay to start with a narrow scope (like "our shared Google
Drive and Slack workspace) and expand later if needed.
    \item \textbf{Agree on Terminology}: Ensure everyone understands basic terms
you will use. For example, define what you mean by asset, threat, vulnerability,
etc., in plain language. This avoids confusion later (a quick glossary on a
whiteboard or shared doc can help).
\end{itemize}

\subsubsection{Participation Tips}

In a small coop, you can do this step in a single meeting where everyone
contributes to the list of assets and goals. In a larger coop, consider sending
a short survey or having breakout groups to gather input, then consolidating the
results in a plenary session. Make sure the final list of assets and scope is
reviewed or approved by the group (e.g. via a show of hands or online poll) so
you have collective agreement on "what we care about protecting. This
collaborative start sets a democratic tone for the whole process.

\subsection{Step 2: Map Systems and Trust Boundaries (How Do We Work?)}
\label{subsec:Step2}

\subsubsection{Purpose}

Create a shared understanding of how information and processes flow in your
coop, and where important trust boundaries lie. Essentially, draw a map of your
organization's sociotechnical system including people, tech, and their
interactions. In threat modeling, this is similar to diagramming your system
architecture and identifying entry points. For a cooperative, it also means
noting social trust assumptions (who/what we trust and in what ways).

\subsubsection{Activities/Checklist}

List Components and Assets:

\begin{itemize}
    \item \textbf{Hardware/Infrastructure}: e.g. member laptops, a server or
NAS, routers, smartphones used for work, IoT devices in the office.
    \item \textbf{Software/Tools}: e.g. the platforms you use – Google Drive,
Slack/Matrix, Nextcloud, Loomio for decisions, etc., as well as any custom
software or website your coop has.
    \item \textbf{Data Stores}: e.g. databases, cloud storage, email archives –
what data is stored and where.
    \item \textbf{People/Roles}: e.g. general members, IT volunteers, finance
coordinators, any outsiders like an accountant or platform provider.
    \item \textbf{Processes}: e.g. how a decision is made (proposal ->
discussion -> vote), how a new member is onboarded, how finances are managed.
\end{itemize}

Write these out, possibly in categories. Essentially, you are enumerating what
pieces make up your organization "system". After that, diagram the Workflow: On
a large paper or using a simple online diagram, sketch how these components
connect. Draw who interacts with what: e.g. members (people) log into the chat
platform (software) to discuss, or the website communicates with a payment
processor. Draw arrows for data flow or interaction: emails sent, files shared,
money transferred, etc. Keep it understandable – you can use simple icons or
just labeled boxes and arrows. Mark any external services (like a third-party
payment gateway or cloud provider) clearly, maybe with a different color or a
cloud icon, since those are partly outside your control.

Identify Trust Boundaries: A trust boundary is a point in the system where the
level of trust changes. For instance:

\begin{itemize}
    \item Between an external user and your internal system: e.g. a public
website vs. your internal database.
    \item Between a regular member and an admin interface: (if any).
    \item Between your organization network and the open internet.
    \item Social trust boundaries: e.g., you trust members not to leak info from
private discussions, or you trust a core team with certain credentials.
\end{itemize}

On your diagram, draw a dotted line or a firewall symbol where these boundaries
are. Essentially ask: At what points do we assume things are safe on one side
and potentially risky on the other? (For example, data inside our Nextcloud is
trusted to be seen by members, but anything coming from outside (like file
uploads from a new user) might be untrusted until checked.)

Document Who Has Access to What: Alongside the map, list which roles or people have
access to which assets. E.g., "Only tech team members can access the server", or "All
members can post in the forum", or "Treasurer has the bank account login". This
helps spotlight any concentrations of access (if one person holds many keys,
that's noted) and areas where trust is placed in individuals. Note External
Dependencies: Write down services or partners you rely on and mark them on the
diagram (for example, your website host, email service, or any software
provider). These are outside your organization but critical; threats can come through
them (a concept known as supply chain or third-party risk).

\subsubsection{Participation Tips}

Building the system map can be a fun group exercise. In a small organization, do it
together on a whiteboard or shared screen, asking everyone to call out
components and connections ("Don't forget we also use Pad for meeting notes!").
In larger organizations, you might have a smaller group draft the diagram (say, an IT
working group or a mix of tech and non-tech members) and then present it to
others for additions and corrections. Make it interactive: people can stick
Post-its on a draft poster or add comments on an online diagram with "Did you
include the volunteer's laptop that runs X?" Keep refining until ,members feel
the map is an accurate picture of "how things work." The final diagram should be
saved in a place where all members can see it, this is now a shared reference
for your threat discussions.

\subsection{Step 3: Identify Threats Collaboratively (What Could Go Wrong?)}
\label{subsec:Step3}

\subsubsection{Purpose}

Brainstorm all the potential threats and bad things that could happen to the
assets and processes you identified. The goal is a comprehensive list of threat
scenarios, covering both technical attacks and social/governance risks. At this
stage, quantity is more important than quality. We want to surface as many
ideas as possible, without judging them yet. This step harnesses the diverse
perspectives in your organization: digitally skilled members might think
of hacking scenarios, whereas others might point out process failures or insider
issues that a pure tech focus could miss.

\subsubsection{Activities/Checklist}

\begin{itemize}

    \item \textbf{Brainstorm in a Safe Environment}:
    
    Gather a group of members (ideally representing different roles or viewpoints in
    the coop) for a threat brainstorming session. Set some ground rules: no idea is
    too small or too "out there," and everyone's input is valued. It's important
    people feel comfortable mentioning even unpleasant hypotheticals ("What if one
    of us turned rogue?") – assure everyone this is about hypothetical situations,
    not personal distrust.

    \item \textbf{Use Prompts and Creative Tools}:
    \begin{itemize}
        \item Walk through the system map from Step 2 and pause at each component or boundary:
        ask "What could go wrong here?" For instance, at the database: "Could someone
        steal or delete this data? Who might and how?" At a boundary like the internet
        connection: "What if an attacker intercepts data here or floods us with
        traffic?"

        \item Introduce the STRIDE categories (a classic security mnemonic) in simple
        terms as a checklist:

        \begin{itemize}
            \item	Spoofing (pretending to be someone else – e.g. fake member login, impersonating an admin),
            \item	Tampering (messing with data or systems – e.g. altering records, defacing the website),
            \item	Repudiation (denying an action – e.g. a member does something and later claims they didn't,
            which is an issue if there's no proof),
            \item	Information Disclosure (leaks – e.g. private member info exposed),
            \item	Denial of Service (disrupting service – e.g. someone takes down your communication channel
            or overloads your server),
            \item	Elevation of Privilege (gaining higher access – e.g. a regular member somehow gets admin
            rights). Use these as thought-starters: "Do we have a risk of someone spoofing identity? Tampering
            with records? etc."
        \end{itemize}    

        \item Use Security Cards (if available) or hypothetical scenario prompts: Security
        Cards are a deck with categories like Attackers' Motivations, Methods, Impacts.
        You can simulate this by asking questions in those dimensions:

        \begin{itemize}
            \item	Motivations: "Who might want to attack us and why? (Ex: for money, for political reasons,
            disgruntled ex-member, random mischief)"
            \item	Methods/Resources: "What skills or tools could they use? (Ex: Phishing emails, malware,
            physical break-in, legal threats, bribes, social engineering phone calls)"
            \item	Impacts: "What would be the impact if they succeeded? (Ex: website down for days, loss of
            member trust, financial loss, legal trouble)"
        \end{itemize}
        
        These prompts help the group consider not just obvious IT threats, but also
        things like internal misuse, mistakes, or external events.
    \end{itemize}

    \item \textbf{Distinguish Different Threat Sources}:
    As ideas emerge, note whether each threat
    scenario is external (coming from outside, e.g. a hacker, a virus, a competitor,
    a random troll) or internal (coming from within the coop, e.g. a member error,
    an insider attack, conflict/miscoordination). Both are important. For example:
    \begin{itemize}
        \item External threat example: "A hacker defaces our website or steals our member list."
        \item Internal threat example: "A coop member accidentally shares a private document publicly,"
        or "Two factions in the coop conflict and someone locks others out of an account."
        \item Hybrid threat: "An external attacker tricks a member (social engineering) to gain access"
        or "An ex-member colludes with an outsider."
    \end{itemize}

    By labeling these, you ensure internal governance vulnerabilities (like abuse of
    trust or poor processes) get attention alongside technical attacks.

    \item \textbf{Write Down Concrete Scenarios}:
    For each idea, capture it as a short scenario description. For instance:

    \begin{itemize}
        \item "Sybil Attack on decision-making:" An attacker (or someone from the community) creates multiple
        fake member accounts to gain extra votes in an online poll, influencing a cooperative decision illicitly.
        \item "Insider data leak:" A discontented member with access to sensitive data decides to leak member
        emails and addresses to the public.
        \item "Ransomware on shared drive:" Malware infects a member's computer and encrypts the shared cloud
        drive files, making them inaccessible until a ransom is paid.
        \item "Lost credentials:" A member who manages the Twitter account leaves suddenly, and no one else has
        the password – the coop loses control of its own social media for a time.
        \item "Miscoordination outage:" In a crisis, no one is designated to respond (because everyone thinks
        someone else will) and a small issue (like a certificate expiry) escalates, taking the website offline
        for days.
        \item "Service provider failure:" The third-party platform (e.g. web host or payment processor) goes
        down or is compromised, affecting the coop's operations.
    \end{itemize}

    Aim for a broad list, covering cyber-attacks, human mistakes, physical events
    (the office gets robbed or a server gets wet), and governance failures. Don't
    worry at this stage if some scenarios seem very unlikely – list them if someone
    is concerned about it.

    \item \textbf{Ensure Social/Process Threats are Included}:
    Cooperatives might face threats like quorum manipulation (exploiting the rules
    of consensus/voting), abuse of emergency powers (someone invoking a crisis to
    grab authority), or "digital vanguard" accumulation (one person quietly gaining
    control of many digital assets because no one else steps up). Include these in
    your brainstorming. For example, "Member X holds all the keys and if they quit
    or go rogue, we're locked out" is a valid threat scenario to record (it's an
    internal risk).

\end{itemize}

\subsubsection{Participation Tips}

Use sticky notes or a shared online document during the brainstorm so everyone
can contribute simultaneously. One approach is to give participants 5–10 minutes
to silently write as many "What if…?" threats as they can (one per sticky note),
then post them and discuss. This helps include those who might be quieter in a
big group. After the brainstorm, group similar threats together (cluster
duplicates) but do not dismiss any threat yet just because it seems minor or
absurd. The point is to capture the collective worries and creative ideas. If
you have a very long list (which is good), you can categorize them into groups
like "Tech Infrastructure," "Member Behavior," "Outsider Attacks,"
"Natural/External," etc., for clarity.

Finally, thank everyone for their ideas – emphasize that all contributions (even
wild ones) help build a complete picture. Save this threat list somewhere
accessible (it becomes an input to later steps). In a coop, making this list
visible (on the wall or online) also signals transparency: everyone sees what
threats are on the radar.


\subsection{Step 4: Profile Adversaries (Who Might Attack Us?)}
\label{subsec:Step4}

\subsubsection{Purpose}

Humanize the threats by creating adversary personas – fictional characters that
represent types of attackers or sources of threats. This helps the group think
from an attacker's perspective ("what would X do?") and ensures you consider the
motivations and capabilities behind the threats. In a cooperative, adversaries
aren't only outside hackers; they could be internal (like a frustrated member)
or systemic (like software bugs or accidents – though we focus on personas for
intentional actors here). Developing these profiles makes later analysis more
concrete and relatable.

\subsubsection{Activities/Checklist}

\begin{itemize}
    \item Identify Key Threat Actors: Look at the threat scenarios from Step 3 and ask, "Who would carry out these
    actions?" You'll likely find a few recurring archetypes. For example:
        \begin{itemize}
            \item A malicious outsider (generic hacker or vandal) with no stake in the coop, just attacking for
            personal gain or fun.
            \item A state or corporate actor who opposes your coop's mission (if relevant politically or
            competitively).
            \item A disgruntled member or ex-member who knows the internal system and might seek revenge or change
            outcomes.
            \item A negligent insider (not malicious, but someone who might make mistakes – although this is more a
            cause of accidents than an "attacker," it's still a persona to consider for unintentional threats).
            \item Technical vs non-technical adversaries: e.g., a script-kiddie hacker with moderate skills, vs. an
            internal activist who might misuse rules rather than code.
        \end{itemize}
    \item Create Persona Descriptions: For each actor type, write a short profile including:
        \begin{itemize}
            \item Name and Role: Give them a nickname that captures their role, like "Mallory the Malicious Member"
            or "Ingrid the Inattentive Intern" or "Oscar the Outside Hacker." This makes it easy to refer to them.
            \item Motivations/Goals: What do they want? Money, disruption of the coop's activities, ideological
            reasons, personal vendetta, thrill? For instance, Mallory (disgruntled ex-member) might be motivated by revenge
            for being voted out of a project, whereas Oscar (outsider) might just want to steal data to sell.
            \item Capabilities/Resources: What skills or resources do they have? Oscar might have hacking tools or know
            how to exploit software. Mallory has insider knowledge of how your coop operates and where the weaknesses in
            process are, but maybe not advanced technical skills. Ingrid (the negligent intern) isn't trying to attack but
            might unknowingly introduce risk by ignoring policies or falling for scams.
            \item Possible Methods: Given their motivation and skills, how might this persona attack or cause an
            incident? E.g., Oscar might use phishing emails or find a bug in your website; Mallory might exploit their
            still-active login or sow misinformation in meetings; Ingrid might click a malicious link or use a weak password
            that gets guessed.
            \item Scenario Tie-In: Connect each persona to one or more of the scenarios from your threat list. For
            example, note that "Sybil attack on voting" would be done by someone like Mallory (if internal) or an outsider
            Sam the Sockpuppet if external. "Ransomware on shared drive" could be set off by Ingrid's mistake or by Oscar
            deliberately.
        \end{itemize}
    \item Document in an Accessible Format: Make one page or slide for each persona. You can even include a
    representative image (e.g., an icon or cartoon; avoid using real people's photos to prevent bias or confusion).
    The idea is to make these threat actors memorable. Write in plain language – this is an internal tool for
    understanding, so it doesn't need to be formal. For example:
    \begin{itemize}   
        \item Persona: Mallory (Disgruntled Ex-Member)
            \begin{itemize}    
                \item Background: Former member who left after a conflict. Still has some credentials left over.
                \item Motivation: Revenge, proving a point about weak security.
                \item Skills/Resources: Knows our systems well, not a hacking expert but savvy enough to abuse any
                oversight. Possibly still in contact with current members (could socially engineer info).
                \item Likely Actions: Try to log in to systems with old account, misuse a still-active access, or spread
                false messages pretending to be someone else (impersonation). Might collude with an outsider for technical help.
                \item Targeted Assets: Member directory (to expose personal info), internal chat (to disrupt
                communications), decision platform (to sway outcomes or just cause chaos).
            \end{itemize}
        \end{itemize}
        Do this for each major adversary types.
    
    \item Include at Least One Insider Persona: It may be uncomfortable but include a scenario of a malicious or
    careless insider. Cooperatives thrive on trust, yet history shows sometimes insiders can cause harm (intentionally
    or not). By creating, say, "Insider Irene" who is well-meaning but prone to bypassing rules, or "Rogue Ray" who
    turns against the group, you can discuss those threats without pointing fingers at a real person. Make it clear
    this is hypothetical to improve security for everyone.
    
    \item Use Personas in Discussion: Once you have personas, you can use them in future steps. For example, when
    thinking about mitigations, you might ask "Would this stop Mallory?" or "How would we detect Oscar's actions?"
    Personas help ground these discussions.
\end{itemize}

\subsubsection{Participation Tips}

Developing personas can be done in small breakout groups, with each group taking
one persona to draft. It's a creative exercise – encourage storytelling, but
keep it grounded in plausibility. After drafting, share with the whole team for
feedback. Non-technical members often contribute richly here ("Actually, a
really angry member might do X, not Y"), and technical members can refine how an
external hacker persona might behave. Keep the tone collaborative and even a bit
playful (people can get quite engaged coming up with hacker nicknames!), but
always tie it back to real threats you identified. In the end, post the personas
alongside the threat list. They become part of your "threat model" documentation
that everyone can reference.

\subsection{Step 5: Analyze Attack Scenarios (How Could Attacks Happen?)}
\label{subsec:Step5}

\subsubsection{Purpose}

Now take your threat list and personas, and dive deeper into how those threats
could play out step-by-step. This scenario analysis helps you understand the
sequence of events in an attack and where your weak points are. In practice,
this means building attack narratives or attack trees and possibly simulating
some scenarios in a tabletop exercise. This step turns abstract threats into
concrete stories, revealing exactly what vulnerabilities enable an attack and
how severe the consequences would be. It's a bridge from brainstorming to
action: by visualizing attacks, you prepare to figure out defenses.

\subsubsection{Activities/Checklist}

\begin{itemize}   
    \item Construct Attack Trees or Flowcharts: Pick a high-priority threat scenario (you will
    prioritize formally in the next step but start with one that seems obviously serious or emblematic).
    For example, take "steal member data" or "Sybil attack on voting". Write that as the attacker's goal
    at the top (root of the tree). Then brainstorm the possible paths to reach that goal. For each path,
    break it into steps:
        \begin{itemize}   
            \item Example: Goal = "Unauthorized person accesses member list." Path 1 might be: External
            hacker exploits a software vulnerability in the database -> gains admin privileges -> extracts the
            data. Path 2: Malicious insider uses their legitimate access -> downloads the data -> shares it out
            of malice. Path 3: Social engineer tricks a member into giving up their password -> logs in as them
            -> navigates to data and copies it.
            \item Draw this as a tree: the goal at top, then branches for each different method, and
            sub-branches for steps/prerequisites. (It can be as simple as bullet indentations if not drawing:
            e.g. a numbered list of steps for each scenario.)
            \item Mark points on the tree where a defense exists or fails. E.g., "Does our system have a
            vulnerability? Possibly if software not up-to-date." Or "Insider route: relies on that member having
            access – do all members have access to full member list? Maybe that's a policy question." This
            highlights vulnerabilities at each step.
            \item Keep the tree at a detail level that's useful – not every keystroke, but significant
            steps and decision points. Two or three levels deep is usually fine (primary ways -> specific
            steps).
        \end{itemize} 
    \item Conduct Tabletop Simulations: For some scenarios, especially ones involving multiple people or
    processes, do a role-play tabletop exercise. Assemble a small group and narratively walk through the
    scenario:
        \begin{itemize}   
            \item Assign someone to play the adversary (using one of your personas) and others to play
            defenders or just observers.
            \item Example: Simulate "Sybil attack during an online vote." Narrator says: "It's the day
            of a big proposal vote. Unknown to the group, Mallory has created three fake member identities over
            the last month." Then step by step: "Vote opens. Mallory votes as herself and as Alice, Bob, and
            Charlie (her fake profiles). The system tallies four votes from what appears to be four people."
            Discuss: Would anything at that moment flag an issue? How would the coop notice? Perhaps another
            member finds it odd that there were three new members who never spoke but voted. Or maybe nobody
            notices until later. Continue: "The vote passes with those extra votes. Later, someone questions the
            outcome…" This kind of storytelling helps highlight if your current processes have detection or not.
            Participants can chime in with "At that point, I would check the member list…" or ask "Do we verify
            new online voters somehow?" Write down these insights.
            \item Another example: "Insider incident response." Simulate what happens if an insider is
            caught doing something suspicious – do you have an agreed response or does chaos ensue?
            \item Or "Server ransomware attack at 2 AM." Who gets the call? Is there a backup? Walk
            through who does what.
        \end{itemize}
    The idea is to practice an attack in theory to see where your response or system breaks. It's
    much cheaper to find gaps this way than during a real incident.
    
    \item Identify Vulnerabilities at Each Step: As you chart out these scenarios, explicitly list the
    vulnerabilities or weak points that make the attack possible. These could be technical (e.g.
    "Outdated plugin allows injection", "No backup exists for database"), or organizational (e.g. "New
    members are not verified, allowing fakes", "Only one person knows how to reset the server"). Also
    note any existing controls and whether they work:
        \begin{itemize}   
            \item For each step in the scenario, ask "What should stop this? Do we have something to
            stop it? Does it actually stop it or can it be bypassed?"
            \item E.g., in the Sybil scenario: Vulnerability = lack of strict member verification in the
            voting system. Existing control = new accounts require admin approval (does that happen? maybe
            someone auto-approved without checks).
            \item In the hacker scenario: Vulnerability = software not patched; Control = we have a
            firewall, but if the attack comes through a web port, firewall doesn't stop it; or Control = we rely
            on strong passwords, which might not help if exploit exists.
            \item Write these vulnerabilities next to the steps or in a separate list mapped to the
            scenario. This will directly feed into deciding mitigations.
        \end{itemize}
    \item Assess Impact and Likelihood for Scenarios: As part of analysis, discuss for each scenario,
    how bad would it be if this happened? and how likely is it to happen? Use qualitative terms (you
    will formalize in next step, but start conversation):
        \begin{itemize}   
            \item Impact: High (e.g. coop might dissolve or face legal action), Medium (painful but
            survivable), Low (minor inconvenience or embarrassment).
            \item Likelihood: High (we've seen attempts or it's easy to do), Medium, Low (requires many
            unlikely failures or very targeted effort).
            \item Example: Ransomware encrypting files – Impact High (work comes to halt, data loss) but
            Likelihood maybe Medium if members are generally careful. Sybil attack – Impact High on governance
            legitimacy, Likelihood Low/Medium depending on how easy it is to create fake accounts in your
            system.
            \item Capture these impressions because they will help when you formally prioritize in Step 6.
        \end{itemize}
    \item Leverage Past Incidents: If your coop or similar groups have experienced incidents,
    incorporate those into scenarios. "This happened before – could it happen again in a worse way?"
    Learning from near-misses or history makes scenarios very concrete. For example, "Last year someone
    guessed our Twitter password – what if they had tweeted offensive stuff? Let's play out that
    scenario."
\end{itemize}

\subsubsection{Participation Tips}

For attack trees, it can help to have a tech-savvy member sketch the first draft
with input, then review with the group to fill gaps. For tabletop simulations,
try to involve a mix of roles – perhaps an IT person, a governance person, and a
regular member. Keep the tone educational, not fearful or accusatory. Encourage
people to "think like an attacker" for a moment – it's often eye-opening for
non-security folks and can be even a bit fun in a serious way. Time-box the
simulation (e.g. 20-30 minutes each) to keep it focused. After each scenario,
have a brief "debrief" discussion: What did we learn? What worked or failed in
our current setup? This will set you up well for the next step, because you'll
have identified where the biggest weaknesses are.

\subsection{Step 6: Prioritize Risks Together (Which Problems Matter Most?)}
\label{subsec:Step6}

\subsubsection{Purpose}

Not all threats are equal. In this step, the cooperative evaluates all the
identified threat scenarios and decides which ones to address first. This is
essentially a risk analysis and ranking. Risk is usually judged by two factors:
how severe the impact would be and how likely the threat is to occur. By scoring
or discussing these, the group can focus on the most critical issues.
Importantly, this is done participatorily – everyone's perspective on what is
important is considered, keeping the process democratic. The output will be a
clear list of top-priority risks that the coop will invest effort in mitigating.

\subsubsection{Activities/Checklist}

\begin{itemize}   
    \item Set Risk Criteria (Impact and Likelihood): As a group, establish a simple shared understanding of
risk levels:

    \begin{itemize}   
        \item Define what High, Medium, Low Impact mean for your coop. For example:
        \begin{itemize}   
            \item High Impact: Threatens the existence of the coop, causes major financial loss or
            legal violation, or fundamentally damages trust (e.g. member personal info exposure, loss of critical systems
            for long time, major public scandal).
            \item Medium Impact: Disruptive and costly, but manageable (e.g. service outage for a day,
            loss of some data that has backups, temporary hit to reputation).
            \item Low Impact: Annoying but minor consequences (e.g. defacement of a webpage, a single
            incorrect transaction that can be fixed).
        \end{itemize}
        \item Define Likelihood similarly:
        \begin{itemize}
            \item High Likelihood: We have evidence or reason to believe this could happen frequently
            or easily (e.g. known attempts have occurred, or known vulnerabilities exist and are unpatched).
            \item Medium: It could happen under certain conditions or if an attacker dedicates effort,
            but not trivial or not seen yet.
            \item Low: Very rare or would require a perfect storm of failures or an extremely capable
            adversary.
        \end{itemize}
        If you prefer numbers, you can rate both on a 1-5 scale or 1-10. But keeping it simple with
        words or a 3-point scale is often fine for organizations, as long as everyone talks through the meanings.
    \end{itemize}

    \item Evaluate Each Threat Scenario: Go through the list of scenarios (from Step 3/5) one by one and discuss:
    \begin{itemize}   
        \item "If this happened, how bad would it be? (Impact)" and "How likely is it to happen given what
        we know? (Likelihood)".
        \item Encourage input: maybe the IT person knows that a certain attack is actually quite hard, so
        likelihood is low; but a governance person might point out that even if low, that attack's impact on member
        trust would be catastrophic. Both points are valid.
        \item You can do this discussion informally and just mark each scenario High/Med/Low, or use a
        more structured method like voting or rating:
        \begin{itemize}   
            \item For instance, create a grid on a whiteboard with Impact on one axis and Likelihood
            on the other, and place each threat (on a sticky note) in the grid where the group thinks it belongs. This
            visual "risk map" often sparks debate ("Should this be higher impact than that?" etc.).
            \item Alternatively, have each member or a small group give a quick rating for each
            scenario anonymously (e.g. via a Google Form or pieces of paper), then average the scores. This can help if
            the group is large to get a baseline, then discuss outliers.
        \end{itemize}
        \item Aim for consensus or at least a general agreement on where each major threat sits (exact
        precision not needed – you mainly want to clearly identify the High-High items).
    \end{itemize}
    
    \item Rank the Risks: Based on the evaluations, identify the top tier of risks that demand action. These
    are typically the scenarios with High impact (even if low likelihood) and those with High likelihood (even if
    medium impact), especially anything that's High in both. Often you'll find a handful that stand out as "we
    absolutely must address these."
    \begin{itemize}   
        \item Also pay attention to "low-hanging fruit" – a scenario that might be Medium risk but can be
        fixed easily. Sometimes the group might say, "This isn't our worst problem, but it's so simple to prevent that
        we should just do it." (Example: "Data loss due to no backup" might be medium likelihood and medium impact,
        but the fix – implement backups – is straightforward, so you might prioritize it early.)
        \item You might end up with categories like: Critical (must fix ASAP), Moderate (plan to address),
        Acceptable or Low (acknowledge but no immediate action).
    \end{itemize}

    \item Document Rationale: For transparency, write down a brief note next to each top risk about why it's
    ranked high and what the group's judgment was. E.g., "Sybil attack on voting – High Impact (could undermine
    our governance legitimacy), Low Likelihood (member sign-up currently requires approval, and we've seen no
    attempts) – Still a Top Concern because of impact on trust." This record helps if later someone asks "Why are
    we focusing on this threat over that one?" Everyone can see the reasoning agreed upon.
    
    \item Verify Against Goals: Revisit Step 1's assets and objectives. Ensure that the top risks you've
    chosen indeed relate to what you care about most. If an important asset has no high risks listed,
    double-check: did we miss a threat for it, or is it truly low-risk? Conversely, if a scenario came up high
    risk but involves something not central to your mission, consider if it's truly a priority. This sanity check
    keeps the process aligned with cooperative values and priorities.
    
    \item Obtain Group Endorsement: Formally or informally, get the group's nod that "Yes, these are the
    threats we're most concerned about." In a smaller coop, that might be as simple as everyone saying "Sounds
    right." In a larger one, you might do a quick vote to approve the risk ranking or have the board/steering
    committee ratify it. This is important for accountability – it shows the decision on what to do next was made
    collectively.
\end{itemize}

\subsubsection{Participation Tips}

Risk prioritization can sometimes lead to debate or disagreement, because people
perceive risks differently. That's okay – the discussion is part of the
participatory process. Ensure that louder voices don't completely drown out
quieter ones; actively ask for input from different members ("We've heard a lot
about technical likelihood – how about the user experience perspective, what do
you think the impact on members would be?"). If consensus is hard, you can fall
back to a vote or averaging scores, as long as the group accepts that outcome.
Remember the principle of democratic decision-making followed by unity in
execution: once the group decides that, say, "Insider data leak" is a top risk
and "DDoS attack on our website" is lower priority, everyone should respect that
and focus on the top risks first. This avoids second-guessing later and ensures
a coherent security effort.

By the end of Step 6, you should have a short list of the most important threats
to tackle, with group support behind that list. Now it's time to figure out how
to mitigate those threats.


\subsection{Step 7: Mitigations and Governance Decisions (How Do We Fix or Prevent Issues?)}
\label{subsec:Step7}

\subsubsection{Purpose}

For each of the top-priority threats, decide on countermeasures and integrate
those decisions into the coop's action plan. In other words, figure out what
security measures to implement and how to approve and enforce them
democratically. This step is where you turn analysis into concrete changes:
technical fixes, new or improved policies, training, etc. It's also where you
make sure that implementing these fixes doesn't accidentally centralize power or
violate cooperative principles. We design the mitigations to both reduce risk
and fit into the coop's governance structure.

\subsubsection{Activities/Checklist}

\begin{itemize}   

    \item Brainstorm Mitigation Options: For each high-priority threat scenario, list possible ways to mitigate
    it. Mitigations can fall into different categories:
        \begin{itemize}   
            \item Technical solutions: e.g. apply a software patch or upgrade, enable two-factor authentication
    for logins, encrypt data at rest, set up an intrusion detection system, require multi-signature for financial
    transactions.
            \item Process or workflow changes: e.g. institute a checklist for onboarding/offboarding members (so
    fake identities are caught and departing members lose access promptly), establish a routine backup procedure,
    require a second pair of eyes (peer review) before pushing changes to the website, add a step to verify any
    important request (like fund transfers) through a secondary channel.
            \item Education and training: e.g. do a phishing awareness session so members can spot suspicious
    emails, create a quick guide on how to choose strong passwords or use the password manager the coop adopts,
    run an orientation on security policies for all members annually.
            \item Governance/policy measures: e.g. create a policy that "All admin passwords are stored in our
    shared password manager vault accessible by at least 3 people," or "For emergency decisions, at least 2 out of
    3 designated responders must agree," or "Every proposal in the decision platform must be made by a verified
    member identity." Essentially, rules that formalize the security practices.
        \end{itemize}
    
    Use the adversary personas as a lens: ask "If we do this, would it stop or deter [Persona] from succeeding?"
    For instance, to counter Mallory (disgruntled ex-member) misusing credentials, one mitigation might be
    "immediately deactivate accounts when someone leaves (offboarding policy)." To counter Oscar (outside hacker)
    exploiting a bug, mitigation is "keep software updated, and maybe run security scans." To counter the Sybil
    scenario, mitigation could be "implement stricter member verification for online voting (like each account
    must link to a real person's membership record)."

    List multiple options if they exist, then discuss feasibility: How hard or expensive is it? Does it require
    outside help or new tools? Does it slow down any workflow (introduce friction)? Does it align with our values
    (e.g. a mitigation "ban all new members for safety" would harm the coop's openness, so probably unacceptable)?
    
    \item Collective Deliberation on Mitigations: For each threat and its potential solutions, discuss with the
    group (or relevant sub-group) to choose the best course of action. This might happen in a dedicated security
    meeting or as part of regular meetings. Ensure to involve those who will be responsible for implementing or
    affected by the change. For example, if the mitigation is "use a new encrypted chat tool," the IT team and
    regular members should both weigh in (IT on how to implement, members on usability).
    Some mitigations might be contentious (maybe someone feels requiring 2FA is too burdensome, or rotating admin
    duties is too chaotic). Strive for consensus by addressing concerns: perhaps provide alternatives or phased
    approaches. If consensus can't be reached, use your coop's normal decision process (majority vote, etc.) to
    finalize the decision on that mitigation.
    Important: Document the decision for each major mitigation: the group agrees "Yes, we will do X to address
    threat Y." This can be recorded in meeting minutes or an action plan.
    
    \item Assign Responsibility and Resources: For each chosen mitigation, decide who will carry it out and by
    when. Since this is a horizontal organization, avoid dumping everything on one person. Instead:
        \begin{itemize}   
            \item Spread technical tasks among tech-skilled members or a tech working group, but maybe pair them
    with a non-tech member for transparency.
            \item Assign policy drafting to a small team that includes people from governance and operations.
            \item If training is needed, maybe identify a member who's good at teaching, or an external expert if
    budget allows.
            \item Ensure each mitigation has an "owner" or small team responsible for seeing it through. This
    distributes responsibility and builds shared security knowledge.
            \item If certain mitigations require budget (e.g. buying a security certificate, or paying for a backup
    service), note that and ensure it goes through the normal budgeting process of the coop.
        \end{itemize}
    
    Essentially, integrate these tasks into your coop's project management – treat them like important initiatives
    with accountability. This also helps avoid the situation where plans are made but no one follows up.
    
    \item Implement with Democratic Oversight: As mitigations are implemented, keep the group informed. For
    example:
        \begin{itemize}   
            \item If the tech team is deploying a new secure tool, they should report progress at meetings or in
    the group chat.
            \item If a policy is drafted (e.g. an "Acceptable Use Policy" for members), circulate it for comments and
    formally adopt it through the coop's decision mechanism.
            \item Unity in execution: Once a security measure is agreed on, all members should cooperate in making it
    work, even if it's a bit inconvenient. This might mean everyone actually enables 2FA on their accounts, or
    actually uses the new password manager, not just a few. Culturally, frame it as "we all agreed to this because
    it protects all of us." When needed, gently remind folks that this was a collective decision (the democratic
    centralism idea: we discussed openly, now we implement uniformly).
        \end{itemize}
    
    \item Plan for Emergency Situations (Temporary Delegation): One big governance aspect to settle is: How will
    we handle a security emergency or critical incident? In a crisis (like an active cyber-attack, or a major
    breach in progress), organizations might need to act faster than usual consensus allows. The protocol encourages
    having a pre-agreed emergency response team or procedure:
        \begin{itemize}   
            \item Decide if you will appoint a small Security Incident Response Team (SIRT) or similar. This could
    be, say, 3 trusted members with the technical know-how (or quick learners) who are empowered to make snap
    decisions when an incident is detected.
            \item Define the scope and limits of their power: e.g., "They can temporarily shut down a server, or
    revoke someone's access, or spend up to X euros on emergency help, without full group approval in that
    moment." Also define the timeframe: their actions are meant to contain the issue, and must be reported ASAP to
    the membership and reviewed, say, within 24-48 hours.
            \item This delegation is temporary and accountable: as soon as the immediate threat is handled, they must
    explain their actions to the whole coop (transparently via an incident report), and if any decision needs to
    be permanent (like firing an IT provider or changing a policy), it goes to the group for normal
    decision-making.
            \item If your coop is small, your "team" might just be the few people who know what to do, but still
    explicitly acknowledge it ("If something blows up, Alice and Bob will take charge for the moment, and inform
    everyone as they do").
        \end{itemize}
    
    Having this plan prevents paralysis in a crisis and avoids someone unilaterally taking over just because
    nothing was defined. Everyone knows in advance who will act and trusts that it's been agreed upon.
    
    \item Integrate Security into Governance Documents: Once decisions are made (normal mitigations or emergency
    roles), codify them. Update your coop's handbook, wiki, or policy docs to include the new security measures.
    For example, add an "Access Control Policy" section that outlines how accounts are managed collectively, or a
    note in the decision-making section that describes the emergency procedure. This ensures new members will
    learn these practices during onboarding, and it institutionalizes the security improvements.
    
    \item Set Review Milestones: Before closing this step, decide when you will check back on these mitigations.
    It could be:
        \begin{itemize}   
            \item A quick check-in at the next general meeting ("Did we do what we said for threat X? Is it
    working?").
            \item A formal review after 3 or 6 months to see progress on longer tasks.
            \item Incorporating it into an annual coop review or similar. By scheduling a follow-up, you create
    accountability and also acknowledge that mitigations may need tweaking.
        \end{itemize}
    
    \end{itemize}
    
\subsubsection{Participation Tips}

Mitigation planning might involve different sub-groups for different items, but
make sure to bring it back to the full coop for transparency. For instance,
let's say a tech group comes up with a plan for backups and multi-sig wallets –
they should present it to others in plain language ("We propose to require two
people to sign off on any expense over 1000€ – here's how that works... do we
all agree?"). Use the coop's normal proposal-and-decision process to adopt
significant changes, so they have legitimacy. Keep records of all these
decisions (perhaps in a Security section of your meeting notes).

Also, acknowledge limitations: the group should be aware of any risks that you
decide not to fully mitigate due to resource constraints. For example, "We know
our website could be DDoS'ed (taken down by an overload attack), but at this
time we can't afford a mitigation for that; we accept that risk and will focus
on higher priorities." Being transparent about accepted risks is part of the
security culture too.

By the end of Step 7, you have an action plan: who will do what to improve
security, and the coop has agreed on these moves. Now the key is to implement
and maintain these practices.


\subsection{Step 8: Ongoing Improvement and Monitoring (How Do we Keep Alive Security?)}
\label{subsec:Step8}

\subsubsection{Purpose}

Threat modeling isn't a one-time project – especially in a cooperative that
evolves. Step 8 is about making security a continuous, integrated part of your
coop's governance and operations. This means regularly monitoring for new
threats, reviewing the effectiveness of your defenses, and adjusting to changes,
all without losing the cooperative spirit. In short: build a living security
program that grows and adapts with your organization.

\subsubsection{Activities/Checklist}

\begin{itemize}   

    \item Include Security in Routine Governance: Treat security as a standing topic in meetings. For
    example:
        \begin{itemize}
            \item In your monthly general meeting or weekly check-in, have a brief agenda item like
            "Security and Privacy Check." This could be a quick report: "Any incidents or near-misses this
            month? Any new vulnerabilities found or new tools added that we should consider in our model?"
            \item Quarterly or semi-annually, do a slightly deeper review. This could coincide with other
            reviews (financial, operational). Go over the threat list: have any new threats emerged? (Perhaps
            the coop started using a new platform – that introduces new risks to consider.) Are there threats
            that can be downgraded because of improvements? Basically, keep the threat model updated.
            \item If you have a rotating security committee, they can take charge of preparing these updates.
            But even if not, someone can volunteer each time to gather relevant info.
        \end{itemize}

    \item Maintain Logs and Audit Trails: Earlier we emphasized logging and traceability. Make sure
    those logs (system logs, decision logs, access records) are actually being looked at. For example:
        \begin{itemize}
            \item If you set up an immutable log of administrative actions (like who changed what settings),
            maybe once a month a couple of members review it to see if all actions were expected and legit.
            \item If you require multi-signature on an account, periodically check that the rule is being
            followed (no one found a shortcut).
            \item Conduct an internal audit once a year: pick a couple of key policies and verify they are
            enforced. E.g., "Check 5 random user accounts to ensure they all have 2FA on as required," or
            "Verify that all ex-members in the past year have indeed been removed from our systems within the
            agreed 24 hours of departure." Such audits can be done by peers (any member can do it following a
            script) and results shared openly: "We checked and found 1 of 5 accounts didn't have 2FA; we helped
            that member set it up."
        \end{itemize}
    This might sound formal, but it can be lightweight and it greatly helps catch when practices slip.
    Because organizations have no boss checking up, the members collectively check up in a transparent way.

    \item Periodic Retraining and Onboarding: Over time, members may forget certain security practices
    or new people join who weren't part of the initial threat modeling. Address this by:
        \begin{itemize}
            \item Creating a short "Security Handbook" or section in your member handbook that summarizes
            key policies ("We use a shared password manager; here's how to get access," "Never share your login
            links with others," "Report any lost device immediately," etc., and also the why – referencing
            threats like "to prevent incidents like [scenario]" which makes it relatable).
            \item Holding a yearly refresher workshop or sending a summary of "Our coop's top 5 threats and how
            we mitigate them – reminders for all members."
            \item Simulating a phishing email test or an impromptu drill (with consent) to keep awareness
            sharp, then discussing the results in a blameless way ("Hey, 3 of us clicked that fake link – let's
            go over how to spot those signs!").
            \item Updating onboarding processes: when new members join, include a quick orientation on security
            norms (for instance, how accounts are created, who to ask for tech help, basic do's and don'ts). If
            they know from day one that "security is everyone's responsibility here," it sets a good culture.
        \end{itemize}

    \item Adapt to Changes in the Coop: If your cooperative grows from 5 members to 50, or starts a new
    project, revisit the threat model more formally. New scale or activities can mean new threats:
        \begin{itemize}
            \item With more members, the risk of insider issues might increase simply by volume, and
            communication overhead grows – maybe you need more structured processes or automation.
            \item With new projects (say you start handling money for members, or you open a second location),
            add those assets and processes to the model and run through the threat steps again in a lighter
            form.
            \item Schedule a full threat modeling redo or refresh perhaps annually or bi-annually. It doesn't
            have to start from scratch each time; you can use the previous notes and just update. But having a
            cycle ensures that, for example, in two years you're not using the exact same assumptions while the
            world changed around you.
        \end{itemize}

    \item Engage with the Wider Community: Horizontal organizations can learn a lot from each other. Consider
    sharing non-sensitive parts of your security approach with other cooperatives or participating in
    forums/discussion groups about security in decentralized organizations. You might discover common
    threats others have seen, or tools specifically helpful for organizations (for example, an open source tool
    for consensus that has anti-Sybil features, etc.). By contributing your experiences (without giving
    away your secrets), you also help the movement as a whole become more secure. This external input
    can be brought back to your coop's next threat modeling session ("We heard another coop had an issue
    with X, should we consider that scenario for us?").

    \item Monitor and Respond to Evolving Threats: Stay informed about general cybersecurity news that
    might affect you (e.g., a new vulnerability in a software you use – ensure someone updates it; a
    wave of phishing targeting small nonprofits – maybe alert members to be extra careful). Since no one
    person is "the security officer," create channels where such information can be shared. Maybe a
    security Slack/Matrix channel or an email list for anyone who finds something relevant. Collective
    eyes can watch more ground.

    \item Governance Feedback Loop: Evaluate how well the balance of democracy and efficiency in your
    security process is working:
        \begin{itemize}
            \item After any incident or even after a year, ask: Did our emergency response plan work? Did
            anyone feel left out of the loop unnecessarily? If so, adjust the protocol.
            \item Are members generally comfortable with the security measures or is there grumbling about
            complexity? If many find it too cumbersome (say the multi-sig process is taking too long for routine
            tasks), maybe tweak the thresholds or invest in a smoother tool. Always weigh these changes against
            the risk: maybe it's fine to ease up if the threat is low, or maybe the group agrees the
            inconvenience is worth the protection.
            \item Essentially, treat the security policies themselves as living documents subject to the coop's
            governance. Amend them when needed, just like you would bylaws or other procedures, through the
            collective decision process.
        \end{itemize}
\end{itemize}

\subsubsection{Participation Tips}

Keeping momentum is often the hardest part – enthusiasm is high during initial
modeling, but can fade. To counter this, make security part of the coop's
culture. Celebrate successes: "We successfully thwarted a phishing attempt
because Maria remembered the training – kudos!" or "Our audit showed 100%
compliance on backups – great job team!" Positive reinforcement shows that these
efforts matter and work. Also, distribute the load: rotate who leads the
security check-in, who runs the next training game, etc., so it's not always one
person driving it (avoid creating a de facto security czar). The more members
have a role over time, the more ingrained it becomes.

\section{Security and Governance Requirements}
\label{sec:security_governance_requirements}

The proposed protocol for horizontal organizations must meet security and
governance requirements that ensure both participatory inclusion and robustness
against internal and external threats. In decentralized structures, where the
absence of formal hierarchy can be seen as both an advantage and a challenge, it
is imperative that the protocol be designed to integrate mechanisms that
preserve horizontality without compromising organizational resilience.
Transparency, in this context, emerges as one of the central pillars
\cite{Colbac}. All events related to the authorization of actions or
modifications must be recorded in an immutable manner, ensuring that actions can
be reliably audited by any member of the organization. These immutable records,
built on technologies such as blockchain or similar cryptographic structures,
ensure traceability and eliminate the possibility of unauthorized changes,
maintaining cohesion between organizational principles and technological
mechanisms.

Democratic participation also plays a fundamental role in the design of the
protocol \cite{Colbac}. In a horizontal organization, decisions must reflect the
collective will, and to this end, the protocol must integrate digital voting
systems that guarantee both the privacy and security of votes \cite{Colbac}. In
addition, it must be possible to temporarily delegate authority to individuals
or groups to deal with situations that require specific expertise, always
ensuring that such delegation can be revoked and that records of actions are
accessible for collective audit \cite{Colbac}.

Another crucial aspect is the flexibility of the protocol, especially in
scenarios where the organization needs to switch between centralized and
distributed governance modes. This transition capacity must be implemented in a
way that the levels of centralization are temporary and properly tracked,
ensuring that control can quickly return to the collective. To this end, the
protocol must provide mechanisms such as emergency tokens, which allow the
execution of critical actions in exceptional situations, as long as such actions
are recorded and subject to retroactive validation by the members of the
organization \cite{Colbac}.

For the protocol to be scalable, it is essential that it supports organizations
of different sizes and degrees of complexity. This includes implementing
distributed validation systems that allow collaborative verification of actions
without burdening individuals or single points of control \cite{Colbac}.
Furthermore, threat modeling should be iterative and adaptive, incorporating
techniques such as simulations based on real-world scenarios to identify
emerging vulnerabilities and adjust countermeasures accordingly. These
mechanisms ensure that the protocol remains functional and effective even when
the organizational scale increases or its internal dynamics change.

\section{Evaluation Strategy}
\label{sec:evaluation_strategy}

The evaluation of the proposed protocol will be conducted through an
experimental and comparative approach, involving real case studies in
organizations with different degrees of horizontality. The main objective is to
validate the effectiveness of the protocol in identifying, mitigating and
preventing threats in horizontal organizational contexts, directly comparing its
performance with established frameworks, such as \gls{stride}.

Candidate organizations will be selected to represent a variety of horizontal
structures, ensuring diversity in power distribution, size and operational
complexity. Participants from each organization will receive structured training
sessions covering both the proposed protocol and \gls{stride}, ensuring
familiarity and a level playing field for comparison.

\textbf{Parallel Threat Modeling Sessions:}
Each organization will conduct simultaneous threat modeling sessions using both
the proposed protocol and \gls{stride} in identical scenarios. These sessions
will be observed to systematically document the process and collect data,
analyzed according to the following clearly defined metrics:

\begin{itemize}
\item \textbf{Precision}: The ratio of valid threats correctly identified to the
total number of threats identified by the protocol.
\item \textbf{Coverage (Recall)}: The proportion of existing threats identified
by the protocol relative to a reference set established by experts.
\item \textbf{Operational Efficiency}: Total time (latency) required to complete
each phase of the threat modeling process, including identification, analysis,
and mitigation planning.
\item \textbf{Usability}: Participants' opinions on the ease of use, clarity,
and overall effort required to learn and effectively apply the protocol.
\end{itemize}

By systematically applying these clearly defined metrics and evaluation steps,
this strategy ensures a comprehensive comparative analysis, providing robust
empirical evidence on the effectiveness of the protocol relative to \gls{stride}
in horizontal organizations.

\section*{}
Chapter 4 presented the preliminary design of a protocol specifically aimed at
threat modeling in horizontal organizations, detailing fundamental security and
governance requirements, such as mechanisms for democratic participation,
temporary delegation of authority, and auditable records. The importance of
aligning technological and organizational processes to ensure robustness against
internal and external threats was highlighted. Based on this conceptual
development, Chapter 5 summarizes the main results achieved by this research,
critically evaluating the proposed protocol, identifying its contributions in
relation to traditional methodologies, and exploring practical scenarios for
future validations in real environments.
