==============================
Title: A Security Threat Brainstorming Toolkit
==============================
CARD TITLES   ADVERSARY’S MOTIVATIONS •Access or Convenience •Curiosity or Boredom •Desire or Obsession •Diplomacy or Warfare •Malice or Revenge •Money •Politics •Protection •Religion •Self-Promotion •World View •Unusual Motivations ADVERSARY’S RESOURCES •Expertise •A Future World •Impunity •Inside Capabilities •Inside Knowledge •Money •Power and Influence •Time •Tools •Unusual Resources ADVERSARY’S METHODS •Attack Cover-Up •Indirect Attack •Manipulation or Coercion •Multi-Phase Attack •Physical Attack •Processes •Technological Attack •Unusual Methods   HUMAN IMPACT •The Biosphere •Emotional Wellbeing •Financial Wellbeing •Personal Data •Physical Wellbeing •Relationships •Societal Wellbeing •Unusual Impacts

HUMAN IMPACT •The Biosphere •Emotional Wellbeing •Financial Wellbeing •Personal Data •Physical Wellbeing •Relationships •Societal Wellbeing •Unusual Impacts

EXAMPLE ACTIVITY Full  writeup and other activities available at securitycards.cs.washington.edu 1. Work in groups of 3-5. 2. Consider an example technology system or a system that you are designing. 3. Go through the deck and familiarize yourself with the dimensions and the cards. Make sure to read at least one card from each dimension in its entirety. 4. Within each dimension, rank cards in order of how relevant their topics are to your system and how much risk they present overall.  5. Why did you rank the cards in that order? 6. Have you surfaced particular attack scenarios? Do particular attacker profiles begin to emerge?

==============================
Title: Attack Trees for Protecting Biometric Systems against Evolving Presentation Attacks
==============================
Proposed by T. Denning, B. Friedman and T. Kohno, theSecurity Cards is a security threat brainstorming toolkit whichconsists of 42 cards divided in four dimensions: HumanImpact, Adversarys Motivations, Adversarys Resources, andAdversarys Methods [21]. This methodology offers a prac-tical way to categorize and evaluate potential vulnerabilitiesof identity collection and management systems. It offers apractical way to collect and organize the information. The goalof this methodology is to understand attack techniques andpatterns already used and postulate those that may be triedin the future. The methodology has to be able to stimulatethinking broadly and creatively about biometric system secu-rity. It is often the case that developers and system maintainersassume they understand all common attack patterns but fail toexplore speciﬁc attack vectors and employ accepted securityprocedures. The ways a deployed system is used or misusedcan introduce unanticipated threats.

Cards pertaining to different dimensions are typically so-licited from stakeholders.• Human Impact explores how security breaches may affecthumans. In case of border security, identity fraud isclearly related to consequences that may not be clear atthe time of security breach. Examples include privacyviolations (damage to identity owners), avoiding legalrepercussions for past actions, or threat for the loss oflife in case of terrorist activities.• Adversary Motivations describe why someone might wantto attack a system. The Security Card methodology helpsus represent possible motivations more concisely, andexpress them with more clarity. The methodology elicitspossible attack motivation that range from ideological,religious and political factors to convenience and self-promotion.• Adversarys Resources analysis explores assets that mightbe widely available and used to launch an identity attack.These resources correspond to hardware and softwaretools, the access to technical or social impersonationexpertise and the ability to inﬂuence the actions of people.For instance, Technical Expertise refers to the potentialtechnical skills of the attacker.• Adversarys Methods explore the high-level approachesthat might be used to perform an attack. Mmanipulationof people, the adherence to burdensome bureaucraticprocesses or speciﬁc exception handling rules (the persondoes not have distinguishable ﬁngerprints, for example)may, in fact, play a role insome of the identity attackvectors.

==============================
Title: Cyber Threat Modeling_ An Evaluation of Three Methods
==============================
STRIDE was developed at Microsoft and represents the state of the practice(a lightweight variant of STRIDE, for instance, was adopted by the Ford MotorCompany). STRIDE involves modeling a system and subsystem and how dataﬂows through the system and subsystem. After that, the methodology relieson a checklist evaluation approach based on the six categories listed above.Subjects who used the STRIDE method did not report a lot of false positives,but the teams generally obtained inconsistent results. The threats reportedseemed to have more to do with the makeup of speciﬁc teams and theirbackground or experience.Based on our initial analysis, STRIDE seems an ideal approach for teams thatdon't have a lot of security expertise because the checklist-based approachconstrains users and limits the potential for false positives. One weakness ofSTRIDE, however, is that it is an onerous task to apply checklists of potentialthreats to the components of the various systems and subsystems.Security Cards. The Security Cards approach moves away from checklist-based approaches like STRIDE and injects more creativity and brainstorminginto cyber threat modeling. The motivation behind this approach is that it canhelp users identify unusual or more sophisticated attacks. Developed at theUniversity of Washington, the Security Cards method relies on physicalresources (i.e., cards) to facilitate brainstorming about potential cyberthreats. Subjects were also asked to include reasoning about attackermotivations and abilities.With Security Cards we found that, overall, the teams of participantsexhibited higher eﬀectiveness. Almost all types of threats were found byteams using Security Cards, but the Security Cards approach also exhibitedgreater variability across teams. This approach, however, produced manyfalse positives. The high number of false positives makes sense becauseusers are encouraged to brainstorm and come up with unusual or atypicalscenarios. Similarly, the performance across teams was dissimilar. Byapplying Security Cards, there weren't many threats that the teams couldn'teventually identify, but each team only found a subset of threats, and thatsubset varied substantially from team to team.

Given our initial results, Security Cards would seem to be an ideal approachin scenarios where a user values a wider spectrum of results over consistentresults.

Persona Non Grata. Developed at DePaul University, the Persona non Grataapproach makes threat modeling more tractable by asking users to focus onattackers, their motivations, and abilities. Once this step is completed, usersare asked to brainstorm about targets and likely attack mechanisms that theattackers would deploy.The theory behind this approach is that if engineers can understand whatcapabilities an attacker may have, and what types of mechanisms they mayuse to compromise a system, the engineers will gain a better understandingof targets or weaknesses within their own systems and the degree to whichthey can be compromised.Some critics of this approach argue that Persona non Grata can often takeusers down the wrong path. For example, for a system related to nationalsecurity, users might reason that the system may be the target of asophisticated attack from another nation state. This conclusion, however,overlooks the fact that a nation state might compromise a system ﬁrstthrough a much simpler entry point and then ratchet up operations fromthere.With Persona non Grata, our research participants reported fewer falsepositives, but they also were unable to gain a comprehensive view ofpotential threats. Their threat modeling tended to consistently produce onlya subset of threat types, which we identiﬁed as a drawback to this approach.While the teams using Persona non Grata did not identify all the threats, thethreats they did identify were reproduced consistently across teams. This isimportant if the aim of threat analysis is to identify a potential threat (withinthat subset) with a [high?] degree of conﬁdence. Moreover, if a threatmodeler has more awareness of the types of vulnerabilities that areimportant in a system, Persona non Grata is ideal because it gives the user ahigher degree of conﬁdence in his or her ability to identify priority threats.

==============================
Title: Keeping Ahead of Our Adversaries
==============================
Threat modeling aims to• identify attackers’ potential abilities and goals and• catalog possible threats that the system must be designed to mitigate.

We consider threat modeling a re-quirements activity. The most beneﬁ t comes from understanding what se-curity requirements are needed and

to be complete and consistent and to truly put themselves in the shoes of an attacker.Security Cards: A Threat Brainstorming ToolkitTo assist threat analysis, Tamara Denning, Batya Friedman, and Ta-dayoshi Kohno developed the Security Cards.7 The Security Cards consist of 42 cards divided into four catego-ries, or dimensions: Human Impact, Adversary’s Motivations, Adversary’s Resources, and Adversary’s Methods.Here, we illustrate how the cards might serve as starting points to ex-plore potential threats to a techno-logical system—in this case, an ICD. This thought exercise is only to ex-plore what these software develop-ment processes would look like when applied to a system concept. We don’t intend to make statements regarding current ICD security or what security considerations have been incorpo-rated into the development process.Human ImpactThis dimension explores how secu-rity breaches could affect humans. The impacts range from personal-privacy violations to widespread societal impact. Threat-modeling sessions could start by ranking the Human Impact cards according to their relevance to the system under consideration. In this case, a highly relevant card is the Physical Well-being card (the first card in Figure 1). It asks us to think about how a misused or compromised ICD could impact people’s physical well-being. However, we could also consider cards such as Emotional Wellbeing (for example, patients are aware of the threat to their health), Financial Wellbeing or Relationships (for ex-ample, the attack aims to discredit

Human ImpactThis dimension explores how secu-rity breaches could affect humans. The impacts range from personal-privacy violations to widespread societal impact. Threat-modeling sessions could start by ranking the Human Impact cards according to their relevance to the system under consideration. In this case, a highly relevant card is the Physical Well-being card (the first card in Figure 1). It asks us to think about how a misused or compromised ICD could impact people’s physical well-being. However, we could also consider cards such as Emotional Wellbeing (for example, patients are aware of the threat to their health), Financial Wellbeing or Relationships (for ex-ample, the attack aims to discredit

the ICD company), or Personal Data (for example, the attacker wants to use the identifying personal data stored on the device).Adversary’s MotivationsThis dimension explores why some-one might want to attack a system. It helps provide a framework to ex-plore a potential attack’s scope and intended targets. For example, the Malice or Revenge card (the sec-ond card in Figure 1) might lead us to consider the situation in which an adversary attacks the ICD user owing to extreme emotion. Other motivation- related cards could in-clude Self-Promotion (for example, the attacker wants to demonstrate technical prowess) or Diplomacy or Warfare (for example, the attacker aims to take down a political enemy who happens to have an ICD). Con-sidering potential adversaries’ mo-tivations helps determine what re-sources they might have and helps us construct attacker proﬁ les.Adversary’s ResourcesThis dimension explores assets an adversary might use to launch an attack. These include hardware and software tools, technical ex-pertise, and various forms of in-ﬂ uence. In this case, we select the Expertise card (the third card in Figure 1) and consider the hacker’s potential technical skills. Another relevant card could be A Future World, which considers potential future attacks, given that interest exists in increasing the capabilities of remote checkups. We might also consider Impunity (for example, the attack might be difﬁ cult to pin on a particular person or to prosecute) or Inside Knowledge (for example, a former employee uses detailed, proprietary knowledge about the architecture).Adversary’s MethodsThis dimension explores how an ad-versary might attack the system, in-cluding technology, coercion, and abusing logistical and bureaucratic processes. We might select the Tech-nological Attack card (the fourth card in Figure 1), given that re-searchers have previously demon-strated such attacks. We also could consider cards such as Multi-Phase Attack (for example, the adversary tampers with software in the doc-tor’s ofﬁ ce responsible for sending commands to the ICD), Indirect At-tack, or Attack Cover-up.From Threats to RequirementsExhaustively cataloging threats is of limited use if we don’t use the in-formation to improve the software we’re developing. To illustrate mov-ing from threats to requirements, suppose our threat model contains the following threat, written from a malicious user’s perspective: “As an IT specialist with intent to physi-cally harm an ICD patient, I’ll launch an attack on the device that will change the intended effects on the patient’s heart.”

